{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m65 packages\u001b[0m \u001b[2min 25ms\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mIgnoring dangling temporary directory: `\u001b[36m/mnt/d/SFSU/CSC871/csc865-anti-money-laundering-ibm/.venv/lib/python3.12/site-packages/~ympy-1.14.0.dist-info\u001b[39m`\u001b[0m\n",
      "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mIgnoring dangling temporary directory: `\u001b[36m/mnt/d/SFSU/CSC871/csc865-anti-money-laundering-ibm/.venv/lib/python3.12/site-packages/~ympy-1.14.0.dist-info\u001b[39m`\u001b[0m\n",
      "\u001b[2mUninstalled \u001b[1m30 packages\u001b[0m \u001b[2min 23.03s\u001b[0m\u001b[0m\n",
      "\u001b[2K░░░░░░░░░░░░░░░░░░░░ [0/2] \u001b[2mInstalling wheels...                                 \u001b[0m\u001b[2mUninstalled \u001b[1m30 packages\u001b[0m \u001b[2min 23.03s\u001b[0m\u001b[0m\n",
      "\u001b[2K░░░░░░░░░░░░░░░░░░░░ [0/2] \u001b[2mInstalling wheels...                                 \u001b[0m\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mFailed to hardlink files; falling back to full copy. This may lead to degraded performance.\n",
      "         If the cache and target directories are on different filesystems, hardlinking may not be supported.\n",
      "         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.\u001b[0m\n",
      "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mFailed to hardlink files; falling back to full copy. This may lead to degraded performance.\n",
      "         If the cache and target directories are on different filesystems, hardlinking may not be supported.\n",
      "         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m2 packages\u001b[0m \u001b[2min 6.98s\u001b[0m\u001b[0m                               \u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1masttokens\u001b[0m\u001b[2m==3.0.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mcomm\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mdebugpy\u001b[0m\u001b[2m==1.8.17\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mdecorator\u001b[0m\u001b[2m==5.2.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mexecuting\u001b[0m\u001b[2m==2.2.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mipykernel\u001b[0m\u001b[2m==7.1.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mipython\u001b[0m\u001b[2m==9.7.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mipython-pygments-lexers\u001b[0m\u001b[2m==1.1.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mjedi\u001b[0m\u001b[2m==0.19.2\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mjupyter-client\u001b[0m\u001b[2m==8.6.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mjupyter-core\u001b[0m\u001b[2m==5.9.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mmatplotlib\u001b[0m\u001b[2m==3.8.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmatplotlib\u001b[0m\u001b[2m==3.10.7\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mmatplotlib-inline\u001b[0m\u001b[2m==0.2.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnest-asyncio\u001b[0m\u001b[2m==1.6.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==1.26.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.3.5\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mparso\u001b[0m\u001b[2m==0.8.5\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpexpect\u001b[0m\u001b[2m==4.9.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpip\u001b[0m\u001b[2m==25.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mplatformdirs\u001b[0m\u001b[2m==4.5.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mprompt-toolkit\u001b[0m\u001b[2m==3.0.52\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mptyprocess\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpure-eval\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpygments\u001b[0m\u001b[2m==2.19.2\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpyzmq\u001b[0m\u001b[2m==27.1.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mseaborn\u001b[0m\u001b[2m==0.13.2\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mstack-data\u001b[0m\u001b[2m==0.6.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mtornado\u001b[0m\u001b[2m==6.5.2\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mtraitlets\u001b[0m\u001b[2m==5.14.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mwcwidth\u001b[0m\u001b[2m==0.2.14\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mwheel\u001b[0m\u001b[2m==0.45.1\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m2 packages\u001b[0m \u001b[2min 6.98s\u001b[0m\u001b[0m                               \u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1masttokens\u001b[0m\u001b[2m==3.0.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mcomm\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mdebugpy\u001b[0m\u001b[2m==1.8.17\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mdecorator\u001b[0m\u001b[2m==5.2.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mexecuting\u001b[0m\u001b[2m==2.2.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mipykernel\u001b[0m\u001b[2m==7.1.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mipython\u001b[0m\u001b[2m==9.7.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mipython-pygments-lexers\u001b[0m\u001b[2m==1.1.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mjedi\u001b[0m\u001b[2m==0.19.2\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mjupyter-client\u001b[0m\u001b[2m==8.6.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mjupyter-core\u001b[0m\u001b[2m==5.9.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mmatplotlib\u001b[0m\u001b[2m==3.8.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmatplotlib\u001b[0m\u001b[2m==3.10.7\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mmatplotlib-inline\u001b[0m\u001b[2m==0.2.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnest-asyncio\u001b[0m\u001b[2m==1.6.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==1.26.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.3.5\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mparso\u001b[0m\u001b[2m==0.8.5\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpexpect\u001b[0m\u001b[2m==4.9.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpip\u001b[0m\u001b[2m==25.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mplatformdirs\u001b[0m\u001b[2m==4.5.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mprompt-toolkit\u001b[0m\u001b[2m==3.0.52\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mptyprocess\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpure-eval\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpygments\u001b[0m\u001b[2m==2.19.2\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpyzmq\u001b[0m\u001b[2m==27.1.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mseaborn\u001b[0m\u001b[2m==0.13.2\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mstack-data\u001b[0m\u001b[2m==0.6.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mtornado\u001b[0m\u001b[2m==6.5.2\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mtraitlets\u001b[0m\u001b[2m==5.14.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mwcwidth\u001b[0m\u001b[2m==0.2.14\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mwheel\u001b[0m\u001b[2m==0.45.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv sync"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Environment ===\n",
      "Platform: Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.31\n",
      "Python: 3.12.11\n",
      "\n",
      "=== PyTorch / CUDA Info ===\n",
      "torch.__version__: 2.9.1+cu128\n",
      "torch.version.cuda: 12.8\n",
      "torch.cuda.is_available(): True\n",
      "torch.cuda.device_count(): 1\n",
      "  device 0: NVIDIA GeForce RTX 5080\n",
      "\n",
      "=== PyTorch / CUDA Info ===\n",
      "torch.__version__: 2.9.1+cu128\n",
      "torch.version.cuda: 12.8\n",
      "torch.cuda.is_available(): True\n",
      "torch.cuda.device_count(): 1\n",
      "  device 0: NVIDIA GeForce RTX 5080\n",
      "\n",
      "Successfully ran a matrix multiply on CUDA.\n",
      "z.device: cuda:0\n",
      "\n",
      "=== Test Complete ===\n",
      "\n",
      "Successfully ran a matrix multiply on CUDA.\n",
      "z.device: cuda:0\n",
      "\n",
      "=== Test Complete ===\n"
     ]
    }
   ],
   "source": [
    "# save as test_cuda.py and run: python3 test_cuda.py\n",
    "\n",
    "import platform\n",
    "\n",
    "print(\"=== Environment ===\")\n",
    "print(\"Platform:\", platform.platform())\n",
    "print(\"Python:\", platform.python_version())\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "except ImportError as e:\n",
    "    print(\"\\nPyTorch is not installed or not in this Python environment.\")\n",
    "    raise SystemExit(e)\n",
    "\n",
    "print(\"\\n=== PyTorch / CUDA Info ===\")\n",
    "print(\"torch.__version__:\", torch.__version__)\n",
    "print(\"torch.version.cuda:\", torch.version.cuda)\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(\"torch.cuda.is_available():\", cuda_available)\n",
    "\n",
    "if not cuda_available:\n",
    "    print(\"\\nCUDA is NOT available to PyTorch in this environment.\")\n",
    "else:\n",
    "    # Number of devices\n",
    "    device_count = torch.cuda.device_count()\n",
    "    print(\"torch.cuda.device_count():\", device_count)\n",
    "\n",
    "    for i in range(device_count):\n",
    "        print(f\"  device {i}: {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "    # Simple tensor test on GPU\n",
    "    try:\n",
    "        x = torch.rand(3, 3, device=\"cuda\")\n",
    "        y = torch.rand(3, 3, device=\"cuda\")\n",
    "        z = x @ y\n",
    "        print(\"\\nSuccessfully ran a matrix multiply on CUDA.\")\n",
    "        print(\"z.device:\", z.device)\n",
    "    except Exception as e:\n",
    "        print(\"\\nERROR: Allocation or compute on CUDA failed:\")\n",
    "        print(e)\n",
    "\n",
    "print(\"\\n=== Test Complete ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1+cu128\n",
      "12.8\n",
      "91002\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5078345 rows; columns: ['Timestamp', 'From Bank', 'Account', 'To Bank', 'Account.1', 'Amount Received', 'Receiving Currency', 'Amount Paid', 'Payment Currency', 'Payment Format', 'Is Laundering']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>From Bank</th>\n",
       "      <th>Account</th>\n",
       "      <th>To Bank</th>\n",
       "      <th>Account.1</th>\n",
       "      <th>Amount Received</th>\n",
       "      <th>Receiving Currency</th>\n",
       "      <th>Amount Paid</th>\n",
       "      <th>Payment Currency</th>\n",
       "      <th>Payment Format</th>\n",
       "      <th>Is Laundering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022/09/01 00:20</td>\n",
       "      <td>10</td>\n",
       "      <td>8000EBD30</td>\n",
       "      <td>10</td>\n",
       "      <td>8000EBD30</td>\n",
       "      <td>3697.34</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>3697.34</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022/09/01 00:20</td>\n",
       "      <td>3208</td>\n",
       "      <td>8000F4580</td>\n",
       "      <td>1</td>\n",
       "      <td>8000F5340</td>\n",
       "      <td>0.01</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>0.01</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Cheque</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022/09/01 00:00</td>\n",
       "      <td>3209</td>\n",
       "      <td>8000F4670</td>\n",
       "      <td>3209</td>\n",
       "      <td>8000F4670</td>\n",
       "      <td>14675.57</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>14675.57</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022/09/01 00:02</td>\n",
       "      <td>12</td>\n",
       "      <td>8000F5030</td>\n",
       "      <td>12</td>\n",
       "      <td>8000F5030</td>\n",
       "      <td>2806.97</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>2806.97</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022/09/01 00:06</td>\n",
       "      <td>10</td>\n",
       "      <td>8000F5200</td>\n",
       "      <td>10</td>\n",
       "      <td>8000F5200</td>\n",
       "      <td>36682.97</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>36682.97</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
       "0  2022/09/01 00:20         10  8000EBD30       10  8000EBD30   \n",
       "1  2022/09/01 00:20       3208  8000F4580        1  8000F5340   \n",
       "2  2022/09/01 00:00       3209  8000F4670     3209  8000F4670   \n",
       "3  2022/09/01 00:02         12  8000F5030       12  8000F5030   \n",
       "4  2022/09/01 00:06         10  8000F5200       10  8000F5200   \n",
       "\n",
       "   Amount Received Receiving Currency  Amount Paid Payment Currency  \\\n",
       "0          3697.34          US Dollar      3697.34        US Dollar   \n",
       "1             0.01          US Dollar         0.01        US Dollar   \n",
       "2         14675.57          US Dollar     14675.57        US Dollar   \n",
       "3          2806.97          US Dollar      2806.97        US Dollar   \n",
       "4         36682.97          US Dollar     36682.97        US Dollar   \n",
       "\n",
       "  Payment Format  Is Laundering  \n",
       "0   Reinvestment              0  \n",
       "1         Cheque              0  \n",
       "2   Reinvestment              0  \n",
       "3   Reinvestment              0  \n",
       "4   Reinvestment              0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to the small transactions CSV (relative to this notebook).\n",
    "DATA_PATH = Path(\"dataset\") / \"HI-Small_Trans.csv\"\n",
    "\n",
    "# Load into a DataFrame\n",
    "small_trans = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Quick summary and preview\n",
    "print(f\"Loaded {len(small_trans)} rows; columns: {list(small_trans.columns)}\")\n",
    "small_trans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imbalance Visualization Overview (IBM AML Dataset)\n",
    "\n",
    "This section adds visual summaries of the strong class imbalance (fraud vs non‑fraud) and related distributions. Run in order after the dataset has been loaded into `small_trans`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "OVERALL LABEL DISTRIBUTION\n",
      "========================================================================\n",
      "Non-fraud (0)  : 5073168 (99.898%)\n",
      "Fraud (1)      :    5177 ( 0.102%)\n",
      "Fraud ratio overall: 0.00102\n",
      "\n",
      "========================================================================\n",
      "NUMERIC AMOUNT SUMMARY PER CLASS\n",
      "========================================================================\n",
      "Column: Amount Received\n",
      "                 count          mean   median           std     min           max\n",
      "Is Laundering                                                                    \n",
      "0              5073168  5.957962e+06  1407.51  1.036563e+09  0.0000  1.046302e+12\n",
      "1                 5177  3.613531e+07  8667.21  1.527919e+09  0.0032  8.485314e+10\n",
      "----------------------------------------\n",
      "Column: Amount Paid\n",
      "                 count          mean   median           std     min           max\n",
      "Is Laundering                                                                    \n",
      "0              5073168  4.477000e+06  1410.99  8.688463e+08  0.0000  1.046302e+12\n",
      "1                 5177  3.613531e+07  8667.21  1.527919e+09  0.0032  8.485314e+10\n",
      "----------------------------------------\n",
      "\n",
      "========================================================================\n",
      "TEMPORAL FRAUD RATES (first 10 windows)\n",
      "========================================================================\n",
      "Column: Amount Received\n",
      "                 count          mean   median           std     min           max\n",
      "Is Laundering                                                                    \n",
      "0              5073168  5.957962e+06  1407.51  1.036563e+09  0.0000  1.046302e+12\n",
      "1                 5177  3.613531e+07  8667.21  1.527919e+09  0.0032  8.485314e+10\n",
      "----------------------------------------\n",
      "Column: Amount Paid\n",
      "                 count          mean   median           std     min           max\n",
      "Is Laundering                                                                    \n",
      "0              5073168  4.477000e+06  1410.99  8.688463e+08  0.0000  1.046302e+12\n",
      "1                 5177  3.613531e+07  8667.21  1.527919e+09  0.0032  8.485314e+10\n",
      "----------------------------------------\n",
      "\n",
      "========================================================================\n",
      "TEMPORAL FRAUD RATES (first 10 windows)\n",
      "========================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3141/2048982089.py:48: FutureWarning: DataFrameGroupBy.resample operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  counts = temp_df.set_index('ts').groupby('label').resample(freq).size().unstack(0).fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using frequency: D\n",
      "            label_0  label_1    total  fraud_rate\n",
      "ts                                               \n",
      "2022-09-01  1114599      322  1114921      0.0003\n",
      "2022-09-02   754041      408   754449      0.0005\n",
      "2022-09-03   206991      391   207382      0.0019\n",
      "2022-09-04   207023      407   207430      0.0020\n",
      "2022-09-05   482179      471   482650      0.0010\n",
      "2022-09-06   481558      531   482089      0.0011\n",
      "2022-09-07   482254      497   482751      0.0010\n",
      "2022-09-08   482234      539   482773      0.0011\n",
      "2022-09-09   653953      514   654467      0.0008\n",
      "2022-09-10   207883      442   208325      0.0021\n",
      "\n",
      "========================================================================\n",
      "ACCOUNT PARTICIPATION SNAPSHOT (top 10)\n",
      "========================================================================\n",
      "Top senders by volume (From Bank):\n",
      "From Bank\n",
      "70     449859\n",
      "10      81629\n",
      "12      79754\n",
      "1       62211\n",
      "15      52511\n",
      "220     52417\n",
      "20      41008\n",
      "3       38413\n",
      "7       31086\n",
      "211     30451\n",
      "\n",
      "Top receivers by volume (To Bank):\n",
      "To Bank\n",
      "10     42547\n",
      "12     41872\n",
      "15     38721\n",
      "220    30625\n",
      "1      30115\n",
      "3      25627\n",
      "7      23029\n",
      "20     22048\n",
      "28     21160\n",
      "211    20576\n",
      "\n",
      "Top senders by fraud count:\n",
      "From Bank\n",
      "70     633\n",
      "12      76\n",
      "20      67\n",
      "119     59\n",
      "10      51\n",
      "1       50\n",
      "11      47\n",
      "15      46\n",
      "22      40\n",
      "118     36\n",
      "\n",
      "Top receivers by fraud count:\n",
      "To Bank\n",
      "12     89\n",
      "119    73\n",
      "11     68\n",
      "20     54\n",
      "1      53\n",
      "10     51\n",
      "22     48\n",
      "222    47\n",
      "23     43\n",
      "15     42\n",
      "\n",
      "\n",
      "========================================================================\n",
      "NUMERIC FEATURE CORRELATIONS WITH FRAUD (top 15 abs(r))\n",
      "========================================================================\n",
      "Top senders by volume (From Bank):\n",
      "From Bank\n",
      "70     449859\n",
      "10      81629\n",
      "12      79754\n",
      "1       62211\n",
      "15      52511\n",
      "220     52417\n",
      "20      41008\n",
      "3       38413\n",
      "7       31086\n",
      "211     30451\n",
      "\n",
      "Top receivers by volume (To Bank):\n",
      "To Bank\n",
      "10     42547\n",
      "12     41872\n",
      "15     38721\n",
      "220    30625\n",
      "1      30115\n",
      "3      25627\n",
      "7      23029\n",
      "20     22048\n",
      "28     21160\n",
      "211    20576\n",
      "\n",
      "Top senders by fraud count:\n",
      "From Bank\n",
      "70     633\n",
      "12      76\n",
      "20      67\n",
      "119     59\n",
      "10      51\n",
      "1       50\n",
      "11      47\n",
      "15      46\n",
      "22      40\n",
      "118     36\n",
      "\n",
      "Top receivers by fraud count:\n",
      "To Bank\n",
      "12     89\n",
      "119    73\n",
      "11     68\n",
      "20     54\n",
      "1      53\n",
      "10     51\n",
      "22     48\n",
      "222    47\n",
      "23     43\n",
      "15     42\n",
      "\n",
      "\n",
      "========================================================================\n",
      "NUMERIC FEATURE CORRELATIONS WITH FRAUD (top 15 abs(r))\n",
      "========================================================================\n",
      "        feature        r  p_value\n",
      "        To Bank -0.00572  0.00000\n",
      "    Amount Paid  0.00116  0.00886\n",
      "Amount Received  0.00093  0.03640\n",
      "      From Bank -0.00023  0.60350\n",
      "        feature        r  p_value\n",
      "        To Bank -0.00572  0.00000\n",
      "    Amount Paid  0.00116  0.00886\n",
      "Amount Received  0.00093  0.03640\n",
      "      From Bank -0.00023  0.60350\n"
     ]
    }
   ],
   "source": [
    "# Text-based imbalance summary for IBM AML dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy.stats import pointbiserialr\n",
    "\n",
    "assert 'small_trans' in globals(), \"Load the dataset into 'small_trans' first (see earlier cell).\"\n",
    "df = small_trans.copy()\n",
    "label_col = 'Is Laundering'\n",
    "if label_col not in df.columns:\n",
    "    raise KeyError(f\"Expected column '{label_col}' in the dataset.\")\n",
    "\n",
    "print('=' * 72)\n",
    "print('OVERALL LABEL DISTRIBUTION')\n",
    "print('=' * 72)\n",
    "label_counts = df[label_col].value_counts().sort_index()\n",
    "total = label_counts.sum()\n",
    "for label, count in label_counts.items():\n",
    "    pct = 100.0 * count / total\n",
    "    label_name = 'Fraud (1)' if label == 1 else 'Non-fraud (0)'\n",
    "    print(f\"{label_name:<15}: {count:>7} ({pct:6.3f}%)\")\n",
    "fraud_ratio = label_counts.get(1, 0) / max(total, 1)\n",
    "print(f\"Fraud ratio overall: {fraud_ratio:.5f}\")\n",
    "\n",
    "print('\\n' + '=' * 72)\n",
    "print('NUMERIC AMOUNT SUMMARY PER CLASS')\n",
    "print('=' * 72)\n",
    "amount_cols = [c for c in df.columns if any(k in c.lower() for k in ('amount', 'amt', 'value'))]\n",
    "if amount_cols:\n",
    "    for col in amount_cols:\n",
    "        series = pd.to_numeric(df[col], errors='coerce')\n",
    "        summary = df.groupby(label_col)[col].agg(['count', 'mean', 'median', 'std', 'min', 'max'])\n",
    "        print(f\"Column: {col}\")\n",
    "        print(summary.fillna(0).round(4).to_string())\n",
    "        print('-' * 40)\n",
    "else:\n",
    "    print('No amount-like columns detected for summary.')\n",
    "\n",
    "print('\\n' + '=' * 72)\n",
    "print('TEMPORAL FRAUD RATES (first 10 windows)')\n",
    "print('=' * 72)\n",
    "time_col = next((c for c in df.columns if any(k in c.lower() for k in ('time', 'date', 'timestamp'))), None)\n",
    "if time_col:\n",
    "    ts = pd.to_datetime(df[time_col], errors='coerce')\n",
    "    temp_df = pd.DataFrame({'ts': ts, 'label': df[label_col]}).dropna(subset=['ts'])\n",
    "    span_days = (temp_df['ts'].max() - temp_df['ts'].min()).days\n",
    "    freq = 'D' if span_days >= 2 else 'H'\n",
    "    counts = temp_df.set_index('ts').groupby('label').resample(freq).size().unstack(0).fillna(0)\n",
    "    counts.columns = [f'label_{c}' for c in counts.columns]\n",
    "    counts['total'] = counts.sum(axis=1)\n",
    "    counts['fraud_rate'] = counts.get('label_1', 0) / counts['total'].replace(0, np.nan)\n",
    "    print(f\"Using frequency: {freq}\")\n",
    "    preview = counts[['label_0', 'label_1', 'total', 'fraud_rate']].head(10).fillna(0)\n",
    "    print(preview.round({'fraud_rate': 4}).to_string())\n",
    "else:\n",
    "    print('No timestamp/date column detected for temporal summary.')\n",
    "\n",
    "print('\\n' + '=' * 72)\n",
    "print('ACCOUNT PARTICIPATION SNAPSHOT (top 10)')\n",
    "print('=' * 72)\n",
    "sender_col = next((c for c in df.columns if any(k in c.lower() for k in ('sender', 'originator', 'from', 'account'))), None)\n",
    "receiver_col = next((c for c in df.columns if any(k in c.lower() for k in ('receiver', 'beneficiary', 'to', 'account.1', 'account_1'))), None)\n",
    "if sender_col and receiver_col:\n",
    "    part_df = df[[sender_col, receiver_col, label_col]].copy()\n",
    "    top_senders = part_df.groupby(sender_col).size().sort_values(ascending=False).head(10)\n",
    "    top_receivers = part_df.groupby(receiver_col).size().sort_values(ascending=False).head(10)\n",
    "    fraud_senders = part_df.groupby(sender_col)[label_col].sum().sort_values(ascending=False).head(10)\n",
    "    fraud_receivers = part_df.groupby(receiver_col)[label_col].sum().sort_values(ascending=False).head(10)\n",
    "    print(f\"Top senders by volume ({sender_col}):\\n{top_senders.to_string()}\\n\")\n",
    "    print(f\"Top receivers by volume ({receiver_col}):\\n{top_receivers.to_string()}\\n\")\n",
    "    print(f\"Top senders by fraud count:\\n{fraud_senders.to_string()}\\n\")\n",
    "    print(f\"Top receivers by fraud count:\\n{fraud_receivers.to_string()}\\n\")\n",
    "else:\n",
    "    print('Could not identify sender/receiver columns for participation snapshot.')\n",
    "\n",
    "print('\\n' + '=' * 72)\n",
    "print('NUMERIC FEATURE CORRELATIONS WITH FRAUD (top 15 abs(r))')\n",
    "print('=' * 72)\n",
    "num_cols = [c for c in df.select_dtypes(include=[np.number]).columns if c != label_col]\n",
    "if num_cols:\n",
    "    corrs = []\n",
    "    y = df[label_col].values\n",
    "    for c in num_cols:\n",
    "        x = pd.to_numeric(df[c], errors='coerce').fillna(0).values\n",
    "        try:\n",
    "            r, p = pointbiserialr(y, x)\n",
    "        except Exception:\n",
    "            r, p = np.nan, np.nan\n",
    "        corrs.append({'feature': c, 'r': r, 'p_value': p})\n",
    "    corr_df = pd.DataFrame(corrs)\n",
    "    corr_df['abs_r'] = corr_df['r'].abs()\n",
    "    corr_df = corr_df.sort_values(by='abs_r', ascending=False).head(15)\n",
    "    print(corr_df[['feature', 'r', 'p_value']].round(5).to_string(index=False))\n",
    "else:\n",
    "    print('No numeric columns (besides label) available for correlation analysis.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert hex account numbers to int\n",
    "hex_to_int = np.vectorize(lambda x: int(x, 16))\n",
    "\n",
    "# create adjacency lists to represent the graph\n",
    "source = hex_to_int(small_trans['Account'])\n",
    "target = hex_to_int(small_trans['Account.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Map account IDs to a compact 0..N-1 index space to avoid huge sparse IDs\n",
    "# Concatenate unique accounts from source/target and factorize\n",
    "all_accounts = np.concatenate([source, target])\n",
    "unique_accounts, inverse_idx = np.unique(all_accounts, return_inverse=True)\n",
    "num_nodes = unique_accounts.shape[0]\n",
    "# Rebuild source/target as compact indices\n",
    "source_idx = inverse_idx[:source.shape[0]]\n",
    "target_idx = inverse_idx[source.shape[0]:]\n",
    "\n",
    "# Build edge_index\n",
    "edge_index = torch.tensor(np.vstack([source_idx, target_idx]), dtype=torch.long)\n",
    "\n",
    "# Create Data object\n",
    "data = Data(edge_index=edge_index, num_nodes=num_nodes)\n",
    "print('num_nodes:', num_nodes, 'num_edges:', edge_index.size(1))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "\n",
    "# extract individual edge features\n",
    "time = pd.to_datetime(small_trans['Timestamp']).astype('int64') / 1e9\n",
    "amount_paid = small_trans['Amount Paid'].to_numpy()\n",
    "amount_received = small_trans['Amount Received'].to_numpy()\n",
    "\n",
    "# use one-hot encoding for categorical variables\n",
    "paid_enc = OneHotEncoder(sparse_output=False)\n",
    "paid_currency = paid_enc.fit_transform(small_trans['Payment Currency'].to_numpy().reshape(-1, 1))\n",
    "\n",
    "received_enc = OneHotEncoder(sparse_output=False)\n",
    "received_currency = received_enc.fit_transform(small_trans['Receiving Currency'].to_numpy().reshape(-1, 1))\n",
    "\n",
    "format_enc = OneHotEncoder(sparse_output=False)\n",
    "pay_format = format_enc.fit_transform(small_trans['Payment Format'].to_numpy().reshape(-1, 1))\n",
    "\n",
    "# combine edge features into single tensor\n",
    "numeric_features = np.column_stack([time, amount_paid, amount_received])\n",
    "#edge_features = torch.from_numpy(np.concatenate([numeric_features, paid_currency, received_currency, pay_format], axis=1)).float()\n",
    "edge_features = torch.from_numpy(numeric_features).float()\n",
    "\n",
    "# create edge labels\n",
    "fraud_label = torch.tensor(small_trans['Is Laundering'].to_numpy(), dtype=torch.long)\n",
    "\n",
    "# attach features and labels to PyG Data\n",
    "data.edge_attr = edge_features\n",
    "data.edge_label = fraud_label\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masks set: 3047007 1015669 1015669\n"
     ]
    }
   ],
   "source": [
    "# chronological 60/20/20 split by edge index order\n",
    "num_edges = data.edge_index.size(1)\n",
    "train_end = int(0.6 * num_edges)\n",
    "val_end = int(0.8 * num_edges)\n",
    "\n",
    "train_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
    "val_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
    "train_mask[:train_end] = True\n",
    "val_mask[train_end:val_end] = True\n",
    "test_mask[val_end:] = True\n",
    "\n",
    "data.train_mask = train_mask\n",
    "data.val_mask = val_mask\n",
    "data.test_mask = test_mask\n",
    "print('Masks set:', train_mask.sum().item(), val_mask.sum().item(), test_mask.sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "#\n",
    "# Increase edge_batch_size if you have ample memory and want fewer edge chunks per epoch.\n",
    "edge_batch_size = 1024\n",
    "# Toggle GPU usage; set to False to keep everything on CPU even if CUDA is visible.\n",
    "use_gpu = torch.cuda.is_available()\n",
    "# Moderated positive class weight to avoid collapsing precision.\n",
    "pos_weight = 75.0\n",
    "# Number of epochs to train for.\n",
    "epochs = 20\n",
    "# Hidden dimension for the GNN and edge classifier.\n",
    "num_hid = 64\n",
    "# Smaller learning rate to keep updates stable on imbalanced data.\n",
    "learn_rate = 5e-5\n",
    "# Weight decay for the optimizer.\n",
    "decay = 1e-4\n",
    "# Gradient clipping threshold (set <=0 to disable).\n",
    "grad_clip = 1.0\n",
    "# Estimated positive label prior; drives threshold calibration during evaluation.\n",
    "pos_label_prior = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PyG GNN model and edge classification training (batched)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import TransformerConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Ensure data object exists with edge_index, edge_attr, edge_label, and masks\n",
    "assert data is not None, 'PyG Data not constructed yet'\n",
    "num_nodes = data.num_nodes\n",
    "num_edges = data.edge_index.size(1)\n",
    "if getattr(data, 'edge_attr', None) is None:\n",
    "    raise RuntimeError('Edge features missing. Run Cell 12 (edge feature construction) before this cell.')\n",
    "edge_feat_dim = data.edge_attr.size(1)\n",
    "\n",
    "# Create simple node features if none exist (e.g., degree or identity)\n",
    "if getattr(data, 'x', None) is None:\n",
    "    deg = torch.zeros((num_nodes, 1), dtype=torch.float)\n",
    "    deg.scatter_add_(0, data.edge_index[0].view(-1,1), torch.ones((num_edges,1)))\n",
    "    data.x = deg  # use degree as a simple node feature\n",
    "\n",
    "class GNN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, edge_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = TransformerConv(in_channels, hidden_channels, edge_dim=edge_dim)\n",
    "        self.conv2 = TransformerConv(hidden_channels, hidden_channels, edge_dim=edge_dim)\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = self.conv1(x, edge_index, edge_attr=edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index, edge_attr=edge_attr)\n",
    "        return x\n",
    "\n",
    "class EdgeClassifier(nn.Module):\n",
    "    def __init__(self, node_hidden, edge_feat_dim, hidden=num_hid, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(node_hidden*2 + edge_feat_dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, num_classes)\n",
    "        )\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        u, v = edge_index\n",
    "        h = torch.cat([x[u], x[v], edge_attr], dim=1)\n",
    "        return self.mlp(h)\n",
    "    def score_pairs(self, x, u, v, edge_attr):\n",
    "        h = torch.cat([x[u], x[v], edge_attr], dim=1)\n",
    "        return self.mlp(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbor sampling backend missing: install 'pyg-lib' (preferred) or 'torch-sparse'.\n",
      "Suggested install command (run in a terminal):\n",
      "/mnt/d/SFSU/CSC871/csc865-anti-money-laundering-ibm/.venv/bin/python -m pip install pyg-lib torch-sparse -f https://data.pyg.org/whl/torch-2.9.1+cu128.html\n",
      "Fallback to full-graph edge training will be used until a backend is installed.\n",
      "Note: pyg_lib currently does not support some newer PyTorch versions; fallback will be used if install fails.\n",
      "Fallback mode active: full-graph embeddings with edge chunks of 2048 (train edges 3047007, val 1015669, test 1015669).\n",
      "edge_batch_size controls chunking in this mode; install pyg-lib or torch-sparse to enable true neighbor sampling.\n"
     ]
    }
   ],
   "source": [
    "import importlib, math, torch, sys, subprocess, os\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "# Detect if neighbor sampling backend (pyg_lib or torch_sparse) is available\n",
    "backend_ok = bool(importlib.util.find_spec(\"pyg_lib\") or importlib.util.find_spec(\"torch_sparse\"))\n",
    "fallback_splits = {}\n",
    "if not backend_ok:\n",
    "    print(\"Neighbor sampling backend missing: install 'pyg-lib' (preferred) or 'torch-sparse'.\")\n",
    "    torch_ver = torch.__version__.split('+')[0]\n",
    "    cuda_ver = torch.version.cuda\n",
    "    if cuda_ver is None:\n",
    "        cuda_tag = 'cpu'\n",
    "    else:\n",
    "        cuda_tag = 'cu' + cuda_ver.replace('.', '')\n",
    "    index_url = f'https://data.pyg.org/whl/torch-{torch_ver}+{cuda_tag}.html'\n",
    "    print('Suggested install command (run in a terminal):')\n",
    "    print(f\"{sys.executable} -m pip install pyg-lib torch-sparse -f {index_url}\")\n",
    "    print('Fallback to full-graph edge training will be used until a backend is installed.')\n",
    "    print('Note: pyg_lib currently does not support some newer PyTorch versions; fallback will be used if install fails.')\n",
    "\n",
    "requested_gpu = use_gpu and torch.cuda.is_available()\n",
    "device = torch.device('cuda') if requested_gpu else torch.device('cpu')\n",
    "if device.type == 'cuda':\n",
    "    dev_index = device.index if device.index is not None else torch.cuda.current_device()\n",
    "    print(f'Using GPU device: {torch.cuda.get_device_name(dev_index)} (index {dev_index}).')\n",
    "else:\n",
    "    if use_gpu and not torch.cuda.is_available():\n",
    "        print('CUDA requested but not available; falling back to CPU.')\n",
    "    else:\n",
    "        print('Using CPU for training (set use_gpu=True and ensure CUDA availability to use GPU).')\n",
    "\n",
    "gnn = GNN(in_channels=data.x.size(1), hidden_channels=num_hid, edge_dim=edge_feat_dim).to(device)\n",
    "clf = EdgeClassifier(node_hidden=num_hid, edge_feat_dim=edge_feat_dim, hidden=num_hid*2, num_classes=2).to(device)\n",
    "\n",
    "params = list(gnn.parameters()) + list(clf.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr=learn_rate, weight_decay=decay)\n",
    "# Ensure class weights are on the same device as the model/tensors\n",
    "class_weights = torch.tensor([1.0, pos_weight], dtype=torch.float, device=device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Build edge_label_index and edge_label tensors for each split\n",
    "train_edge_label_index = data.edge_index[:, data.train_mask]\n",
    "train_edge_label = data.edge_label[data.train_mask]\n",
    "\n",
    "val_edge_label_index = data.edge_index[:, data.val_mask]\n",
    "val_edge_label = data.edge_label[data.val_mask]\n",
    "\n",
    "test_edge_label_index = data.edge_index[:, data.test_mask]\n",
    "test_edge_label = data.edge_label[data.test_mask]\n",
    "\n",
    "# Safer defaults for batch size & neighbors to reduce per-batch time/memory\n",
    "batch_size = edge_batch_size  # configurable via hyperparameter cell\n",
    "num_neighbors = [10, 5]  # fewer neighbors for smaller subgraphs\n",
    "\n",
    "fallback_mode = not backend_ok\n",
    "if backend_ok:\n",
    "    print(f'Backend OK: {backend_ok} | batch_size: {batch_size} | num_neighbors: {num_neighbors}')\n",
    "    train_loader = LinkNeighborLoader(\n",
    "        data,\n",
    "        num_neighbors=num_neighbors,\n",
    "        batch_size=batch_size,\n",
    "        edge_label_index=train_edge_label_index,\n",
    "        edge_label=train_edge_label,\n",
    "        shuffle=True,\n",
    "        neg_sampling_ratio=0.0\n",
    "    )\n",
    "    val_loader = LinkNeighborLoader(\n",
    "        data,\n",
    "        num_neighbors=num_neighbors,\n",
    "        batch_size=batch_size,\n",
    "        edge_label_index=val_edge_label_index,\n",
    "        edge_label=val_edge_label,\n",
    "        shuffle=False,\n",
    "        neg_sampling_ratio=0.0\n",
    "    )\n",
    "    test_loader = LinkNeighborLoader(\n",
    "        data,\n",
    "        num_neighbors=num_neighbors,\n",
    "        batch_size=batch_size,\n",
    "        edge_label_index=test_edge_label_index,\n",
    "        edge_label=test_edge_label,\n",
    "        shuffle=False,\n",
    "        neg_sampling_ratio=0.0\n",
    "    )\n",
    "else:\n",
    "    def _split_edges(mask):\n",
    "        return {\n",
    "            'edge_label_index': data.edge_index[:, mask],\n",
    "            'edge_label': data.edge_label[mask],\n",
    "            'edge_attr': data.edge_attr[mask]\n",
    "        }\n",
    "    fallback_splits = {\n",
    "        'train': _split_edges(data.train_mask),\n",
    "        'val': _split_edges(data.val_mask),\n",
    "        'test': _split_edges(data.test_mask)\n",
    "    }\n",
    "    train_loader = fallback_splits['train']\n",
    "    val_loader = fallback_splits['val']\n",
    "    test_loader = fallback_splits['test']\n",
    "    train_count = fallback_splits['train']['edge_label'].numel()\n",
    "    val_count = fallback_splits['val']['edge_label'].numel()\n",
    "    test_count = fallback_splits['test']['edge_label'].numel()\n",
    "    chunk_size = max(int(edge_batch_size), 1)\n",
    "    print(f'Fallback mode active on {device.type.upper()} device: full-graph embeddings with edge chunks of {chunk_size} (train edges {train_count}, val {val_count}, test {test_count}).')\n",
    "    print('edge_batch_size controls chunking in this mode; install pyg-lib or torch-sparse to enable true neighbor sampling.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | loss 1160.7900 | time 21.8s | train_acc 0.003 | val_acc 0.004 | val_precision 0.001 | val_recall 0.995 | val_f1 0.002\n",
      "Epoch 02 | loss 896.0501 | time 22.1s | train_acc 0.003 | val_acc 0.004 | val_precision 0.001 | val_recall 0.995 | val_f1 0.002\n",
      "Epoch 02 | loss 896.0501 | time 22.1s | train_acc 0.003 | val_acc 0.004 | val_precision 0.001 | val_recall 0.995 | val_f1 0.002\n",
      "Epoch 04 | loss 510.8736 | time 18.0s | train_acc 0.005 | val_acc 0.006 | val_precision 0.001 | val_recall 0.995 | val_f1 0.002\n",
      "Epoch 04 | loss 510.8736 | time 18.0s | train_acc 0.005 | val_acc 0.006 | val_precision 0.001 | val_recall 0.995 | val_f1 0.002\n",
      "Epoch 06 | loss 218.7987 | time 16.7s | train_acc 0.106 | val_acc 0.132 | val_precision 0.001 | val_recall 0.887 | val_f1 0.002\n",
      "Epoch 06 | loss 218.7987 | time 16.7s | train_acc 0.106 | val_acc 0.132 | val_precision 0.001 | val_recall 0.887 | val_f1 0.002\n",
      "Epoch 08 | loss 139.9285 | time 17.2s | train_acc 0.123 | val_acc 0.154 | val_precision 0.001 | val_recall 0.889 | val_f1 0.002\n",
      "Epoch 08 | loss 139.9285 | time 17.2s | train_acc 0.123 | val_acc 0.154 | val_precision 0.001 | val_recall 0.889 | val_f1 0.002\n",
      "Epoch 10 | loss 119.4870 | time 15.9s | train_acc 0.133 | val_acc 0.167 | val_precision 0.001 | val_recall 0.883 | val_f1 0.002\n",
      "Epoch 10 | loss 119.4870 | time 15.9s | train_acc 0.133 | val_acc 0.167 | val_precision 0.001 | val_recall 0.883 | val_f1 0.002\n",
      "Epoch 12 | loss 82.6620 | time 15.5s | train_acc 0.183 | val_acc 0.214 | val_precision 0.001 | val_recall 0.791 | val_f1 0.002\n",
      "Epoch 12 | loss 82.6620 | time 15.5s | train_acc 0.183 | val_acc 0.214 | val_precision 0.001 | val_recall 0.791 | val_f1 0.002\n",
      "Epoch 14 | loss 62.8628 | time 16.3s | train_acc 0.162 | val_acc 0.186 | val_precision 0.001 | val_recall 0.794 | val_f1 0.002\n",
      "Epoch 14 | loss 62.8628 | time 16.3s | train_acc 0.162 | val_acc 0.186 | val_precision 0.001 | val_recall 0.794 | val_f1 0.002\n",
      "Epoch 16 | loss 20.2726 | time 18.8s | train_acc 0.029 | val_acc 0.019 | val_precision 0.001 | val_recall 0.948 | val_f1 0.002\n",
      "Epoch 16 | loss 20.2726 | time 18.8s | train_acc 0.029 | val_acc 0.019 | val_precision 0.001 | val_recall 0.948 | val_f1 0.002\n",
      "Epoch 18 | loss 90.0304 | time 16.7s | train_acc 0.027 | val_acc 0.015 | val_precision 0.001 | val_recall 0.946 | val_f1 0.002\n",
      "Epoch 18 | loss 90.0304 | time 16.7s | train_acc 0.027 | val_acc 0.015 | val_precision 0.001 | val_recall 0.946 | val_f1 0.002\n",
      "Epoch 20 | loss 99.6998 | time 17.5s | train_acc 0.030 | val_acc 0.016 | val_precision 0.001 | val_recall 0.943 | val_f1 0.002\n",
      "Epoch 20 | loss 99.6998 | time 17.5s | train_acc 0.030 | val_acc 0.016 | val_precision 0.001 | val_recall 0.943 | val_f1 0.002\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import math\n",
    "import gc\n",
    "from contextlib import nullcontext\n",
    "\n",
    "\n",
    "def _gather_label_edge_attr(batch):\n",
    "    # Map local edges (u,v) -> position in batch.edge_index to gather edge_attr for labeled edges\n",
    "    e_u = batch.edge_index[0].tolist()\n",
    "    e_v = batch.edge_index[1].tolist()\n",
    "    pos_map = {(eu, ev): i for i, (eu, ev) in enumerate(zip(e_u, e_v))}\n",
    "    lu = batch.edge_label_index[0].tolist()\n",
    "    lv = batch.edge_label_index[1].tolist()\n",
    "    idx = [pos_map[(u, v)] for u, v in zip(lu, lv)]\n",
    "    return batch.edge_attr[idx]\n",
    "\n",
    "\n",
    "def _iter_fallback_chunks(split, chunk_size):\n",
    "    edge_index = split['edge_label_index']\n",
    "    edge_attr = split['edge_attr']\n",
    "    edge_label = split['edge_label']\n",
    "    total = edge_label.size(0)\n",
    "    for start in range(0, total, chunk_size):\n",
    "        end = min(start + chunk_size, total)\n",
    "        yield edge_index[:, start:end], edge_attr[start:end], edge_label[start:end]\n",
    "\n",
    "\n",
    "def _apply_prior_threshold(probabilities, prior):\n",
    "    probs = probabilities.detach().float().cpu()\n",
    "    if probs.numel() == 0:\n",
    "        zeros = torch.zeros_like(probs, dtype=torch.long)\n",
    "        return 0.5, zeros\n",
    "    if prior is None or prior <= 0 or prior >= 1:\n",
    "        threshold = 0.5\n",
    "    else:\n",
    "        num_pos = max(int(math.ceil(prior * probs.numel())), 1)\n",
    "        num_pos = min(num_pos, probs.numel())\n",
    "        sorted_probs, _ = torch.sort(probs)\n",
    "        threshold = float(sorted_probs[-num_pos])\n",
    "    preds = (probs >= threshold).long()\n",
    "    return float(max(min(threshold, 1.0), 0.0)), preds\n",
    "\n",
    "\n",
    "def train_one_epoch(use_amp=True, log_every=200):\n",
    "    gnn.train(); clf.train()\n",
    "    amp_enabled = use_amp and (device.type == 'cuda') and not fallback_mode\n",
    "    scaler = torch.amp.GradScaler('cuda') if amp_enabled else None\n",
    "    clip_enabled = (grad_clip is not None) and (grad_clip > 0)\n",
    "    if fallback_mode:\n",
    "        optimizer.zero_grad()\n",
    "        x = gnn(data.x.to(device), data.edge_index.to(device), data.edge_attr.to(device))\n",
    "        split = fallback_splits['train']\n",
    "        total_edges = split['edge_label'].numel()\n",
    "        chunk_size = max(int(edge_batch_size), 1)\n",
    "        loss_terms = []\n",
    "        for edge_idx_chunk, edge_attr_chunk, label_chunk in _iter_fallback_chunks(split, chunk_size):\n",
    "            u = edge_idx_chunk[0].to(device)\n",
    "            v = edge_idx_chunk[1].to(device)\n",
    "            edge_attr = torch.nan_to_num(edge_attr_chunk, nan=0.0, posinf=0.0, neginf=0.0).to(device)\n",
    "            edge_label = label_chunk.to(device)\n",
    "            logits = clf.score_pairs(x, u, v, edge_attr)\n",
    "            loss = criterion(logits, edge_label)\n",
    "            if not torch.isfinite(loss):\n",
    "                print('Non-finite loss encountered in fallback chunk; try lowering pos_weight or learning rate.')\n",
    "                return float('nan')\n",
    "            loss_terms.append(loss * edge_label.numel())\n",
    "        if not loss_terms:\n",
    "            print('No training edges available in fallback mode; skipping epoch.')\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            return 0.0\n",
    "        loss_total = torch.stack(loss_terms).sum() / max(total_edges, 1)\n",
    "        loss_total.backward()\n",
    "        if clip_enabled:\n",
    "            torch.nn.utils.clip_grad_norm_(params, max_norm=grad_clip)\n",
    "        optimizer.step()\n",
    "        return float(loss_total.detach().cpu())\n",
    "    # Neighbor-sampling path (backend available)\n",
    "    total_loss = 0.0\n",
    "    total_count = 0\n",
    "    t0 = time.time()\n",
    "    for i, batch in enumerate(tqdm(train_loader, desc='train_batches'), 1):\n",
    "        optimizer.zero_grad()\n",
    "        batch = batch.to(device)\n",
    "        context = torch.amp.autocast('cuda') if scaler is not None else nullcontext()\n",
    "        with context:\n",
    "            x = gnn(batch.x, batch.edge_index, batch.edge_attr)\n",
    "            label_edge_attr = _gather_label_edge_attr(batch)\n",
    "            logits = clf.score_pairs(x, batch.edge_label_index[0], batch.edge_label_index[1], label_edge_attr)\n",
    "            loss = criterion(logits, batch.edge_label)\n",
    "        if not torch.isfinite(loss):\n",
    "            print(f'  batch {i} produced non-finite loss; skipping update.')\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            continue\n",
    "        if scaler is not None:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            if clip_enabled:\n",
    "                torch.nn.utils.clip_grad_norm_(params, max_norm=grad_clip)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            if clip_enabled:\n",
    "                torch.nn.utils.clip_grad_norm_(params, max_norm=grad_clip)\n",
    "            optimizer.step()\n",
    "        batch_size_local = batch.edge_label.numel()\n",
    "        total_loss += loss.item() * batch_size_local\n",
    "        total_count += batch_size_local\n",
    "        if i % max(log_every, 1) == 0:\n",
    "            print(f'  batch {i} | batch_loss {loss.item():.4f} | elapsed {time.time()-t0:.1f}s')\n",
    "    return total_loss / max(total_count, 1)\n",
    "\n",
    "\n",
    "def evaluate_split(split_name):\n",
    "    gnn.eval(); clf.eval()\n",
    "    if fallback_mode:\n",
    "        split = fallback_splits[split_name]\n",
    "        chunk_size = max(int(edge_batch_size), 1)\n",
    "        probs_list = []\n",
    "        labels_list = []\n",
    "        with torch.no_grad():\n",
    "            x = gnn(data.x.to(device), data.edge_index.to(device), data.edge_attr.to(device))\n",
    "            for edge_idx_chunk, edge_attr_chunk, label_chunk in _iter_fallback_chunks(split, chunk_size):\n",
    "                u = edge_idx_chunk[0].to(device)\n",
    "                v = edge_idx_chunk[1].to(device)\n",
    "                edge_attr = torch.nan_to_num(edge_attr_chunk, nan=0.0, posinf=0.0, neginf=0.0).to(device)\n",
    "                logits = clf.score_pairs(x, u, v, edge_attr)\n",
    "                probs_list.append(torch.softmax(logits, dim=1)[:, 1].detach().cpu())\n",
    "                labels_list.append(label_chunk.detach().cpu())\n",
    "        if not labels_list:\n",
    "            return 0.0, np.array([]), np.array([]), np.array([]), 0.5\n",
    "        labels = torch.cat(labels_list)\n",
    "        probs = torch.cat(probs_list)\n",
    "        threshold, preds_tensor = _apply_prior_threshold(probs, pos_label_prior)\n",
    "        acc = (preds_tensor == labels).sum().item() / max(labels.numel(), 1)\n",
    "        return acc, labels.numpy(), preds_tensor.numpy(), probs.numpy(), threshold\n",
    "    loader_map = {'train': train_loader, 'val': val_loader, 'test': test_loader}\n",
    "    loader = loader_map[split_name]\n",
    "    probs_accum = []\n",
    "    labels_accum = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=f'{split_name}_batches'):\n",
    "            batch = batch.to(device)\n",
    "            x = gnn(batch.x, batch.edge_index, batch.edge_attr)\n",
    "            label_edge_attr = _gather_label_edge_attr(batch)\n",
    "            logits = clf.score_pairs(x, batch.edge_label_index[0], batch.edge_label_index[1], label_edge_attr)\n",
    "            probs_accum.append(torch.softmax(logits, dim=1)[:, 1].detach().cpu())\n",
    "            labels_accum.append(batch.edge_label.detach().cpu())\n",
    "    if not labels_accum:\n",
    "        return 0.0, np.array([]), np.array([]), np.array([]), 0.5\n",
    "    labels = torch.cat(labels_accum)\n",
    "    probs = torch.cat(probs_accum)\n",
    "    threshold, preds_tensor = _apply_prior_threshold(probs, pos_label_prior)\n",
    "    acc = (preds_tensor == labels).sum().item() / max(labels.numel(), 1)\n",
    "    return acc, labels.numpy(), preds_tensor.numpy(), probs.numpy(), threshold\n",
    "\n",
    "\n",
    "log_every = 200 if not fallback_mode else 0\n",
    "for epoch in range(1, epochs+1):\n",
    "    epoch_t0 = time.time()\n",
    "    avg_loss = train_one_epoch(use_amp=(device.type == 'cuda'), log_every=log_every)\n",
    "    epoch_time = time.time() - epoch_t0\n",
    "    if not math.isfinite(avg_loss):\n",
    "        print(f'Epoch {epoch:02d} skipped due to non-finite loss.')\n",
    "        continue\n",
    "    if epoch % 2 == 0 or epoch == 1:\n",
    "        train_acc, _, _, _, _ = evaluate_split('train')\n",
    "        val_acc, y_val, p_val, _, val_threshold = evaluate_split('val')\n",
    "        if y_val.size > 0:\n",
    "            pr, rc, f1, _ = precision_recall_fscore_support(y_val, p_val, average='binary', zero_division=0)\n",
    "            val_pos_rate = float(p_val.mean())\n",
    "        else:\n",
    "            pr = rc = f1 = 0.0\n",
    "            val_pos_rate = 0.0\n",
    "        print(f'Epoch {epoch:02d} | loss {avg_loss:.4f} | time {epoch_time:.1f}s | train_acc {train_acc:.3f} | val_acc {val_acc:.3f} | val_precision {pr:.3f} | val_recall {rc:.3f} | val_f1 {f1:.3f} | val_thresh {val_threshold:.3f} | val_pos_frac {val_pos_rate:.5f}')\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AcceleratorError",
     "evalue": "CUDA error: unknown error\nSearch for `cudaErrorUnknown' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAcceleratorError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m test_acc, y_test, p_test = \u001b[43mevaluate_split\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtest\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m cm = confusion_matrix(y_test, p_test) \u001b[38;5;28;01mif\u001b[39;00m y_test.size > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mTest accuracy:\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mround\u001b[39m(test_acc, \u001b[32m6\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 101\u001b[39m, in \u001b[36mevaluate_split\u001b[39m\u001b[34m(split_name)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m edge_idx_chunk, edge_attr_chunk, label_chunk \u001b[38;5;129;01min\u001b[39;00m _iter_fallback_chunks(split, chunk_size):\n\u001b[32m    100\u001b[39m     u = edge_idx_chunk[\u001b[32m0\u001b[39m].to(device)\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     v = \u001b[43medge_idx_chunk\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m     edge_attr = torch.nan_to_num(edge_attr_chunk, nan=\u001b[32m0.0\u001b[39m, posinf=\u001b[32m0.0\u001b[39m, neginf=\u001b[32m0.0\u001b[39m).to(device)\n\u001b[32m    103\u001b[39m     logits = clf.score_pairs(x, u, v, edge_attr)\n",
      "\u001b[31mAcceleratorError\u001b[39m: CUDA error: unknown error\nSearch for `cudaErrorUnknown' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "test_acc, y_test, p_test, test_probs, test_thresh = evaluate_split('test')\n",
    "cm = confusion_matrix(y_test, p_test) if y_test.size > 0 else None\n",
    "print('Test accuracy:', round(test_acc, 6))\n",
    "print('Test threshold:', round(float(test_thresh), 6))\n",
    "print('Predicted positive fraction:', round(float(p_test.mean()) if p_test.size > 0 else 0.0, 6))\n",
    "\n",
    "# Derive recall and FPR from confusion matrix if available\n",
    "if cm is not None and cm.shape == (2,2):\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    recall = tp / max(tp + fn, 1)\n",
    "    fpr = fp / max(fp + tn, 1)\n",
    "    print('Test recall', round(float(recall), 6))\n",
    "    print('False positive rate', round(float(fpr), 6))\n",
    "    ConfusionMatrixDisplay(cm).plot()\n",
    "else:\n",
    "    print('Not enough classes in test to compute CM/recall/FPR.')\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOv070Al0cK/8N1oI0v7dEu",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "csc865-anti-money-laundering-ibm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
