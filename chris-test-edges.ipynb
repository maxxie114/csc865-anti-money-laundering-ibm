{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m65 packages\u001b[0m \u001b[2min 25ms\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mIgnoring dangling temporary directory: `\u001b[36m/mnt/d/SFSU/CSC871/csc865-anti-money-laundering-ibm/.venv/lib/python3.12/site-packages/~ympy-1.14.0.dist-info\u001b[39m`\u001b[0m\n",
      "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mIgnoring dangling temporary directory: `\u001b[36m/mnt/d/SFSU/CSC871/csc865-anti-money-laundering-ibm/.venv/lib/python3.12/site-packages/~ympy-1.14.0.dist-info\u001b[39m`\u001b[0m\n",
      "\u001b[2mUninstalled \u001b[1m30 packages\u001b[0m \u001b[2min 23.03s\u001b[0m\u001b[0m\n",
      "\u001b[2K░░░░░░░░░░░░░░░░░░░░ [0/2] \u001b[2mInstalling wheels...                                 \u001b[0m\u001b[2mUninstalled \u001b[1m30 packages\u001b[0m \u001b[2min 23.03s\u001b[0m\u001b[0m\n",
      "\u001b[2K░░░░░░░░░░░░░░░░░░░░ [0/2] \u001b[2mInstalling wheels...                                 \u001b[0m\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mFailed to hardlink files; falling back to full copy. This may lead to degraded performance.\n",
      "         If the cache and target directories are on different filesystems, hardlinking may not be supported.\n",
      "         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.\u001b[0m\n",
      "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mFailed to hardlink files; falling back to full copy. This may lead to degraded performance.\n",
      "         If the cache and target directories are on different filesystems, hardlinking may not be supported.\n",
      "         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m2 packages\u001b[0m \u001b[2min 6.98s\u001b[0m\u001b[0m                               \u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1masttokens\u001b[0m\u001b[2m==3.0.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mcomm\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mdebugpy\u001b[0m\u001b[2m==1.8.17\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mdecorator\u001b[0m\u001b[2m==5.2.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mexecuting\u001b[0m\u001b[2m==2.2.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mipykernel\u001b[0m\u001b[2m==7.1.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mipython\u001b[0m\u001b[2m==9.7.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mipython-pygments-lexers\u001b[0m\u001b[2m==1.1.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mjedi\u001b[0m\u001b[2m==0.19.2\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mjupyter-client\u001b[0m\u001b[2m==8.6.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mjupyter-core\u001b[0m\u001b[2m==5.9.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mmatplotlib\u001b[0m\u001b[2m==3.8.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmatplotlib\u001b[0m\u001b[2m==3.10.7\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mmatplotlib-inline\u001b[0m\u001b[2m==0.2.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnest-asyncio\u001b[0m\u001b[2m==1.6.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==1.26.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.3.5\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mparso\u001b[0m\u001b[2m==0.8.5\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpexpect\u001b[0m\u001b[2m==4.9.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpip\u001b[0m\u001b[2m==25.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mplatformdirs\u001b[0m\u001b[2m==4.5.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mprompt-toolkit\u001b[0m\u001b[2m==3.0.52\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mptyprocess\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpure-eval\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpygments\u001b[0m\u001b[2m==2.19.2\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpyzmq\u001b[0m\u001b[2m==27.1.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mseaborn\u001b[0m\u001b[2m==0.13.2\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mstack-data\u001b[0m\u001b[2m==0.6.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mtornado\u001b[0m\u001b[2m==6.5.2\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mtraitlets\u001b[0m\u001b[2m==5.14.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mwcwidth\u001b[0m\u001b[2m==0.2.14\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mwheel\u001b[0m\u001b[2m==0.45.1\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m2 packages\u001b[0m \u001b[2min 6.98s\u001b[0m\u001b[0m                               \u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1masttokens\u001b[0m\u001b[2m==3.0.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mcomm\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mdebugpy\u001b[0m\u001b[2m==1.8.17\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mdecorator\u001b[0m\u001b[2m==5.2.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mexecuting\u001b[0m\u001b[2m==2.2.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mipykernel\u001b[0m\u001b[2m==7.1.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mipython\u001b[0m\u001b[2m==9.7.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mipython-pygments-lexers\u001b[0m\u001b[2m==1.1.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mjedi\u001b[0m\u001b[2m==0.19.2\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mjupyter-client\u001b[0m\u001b[2m==8.6.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mjupyter-core\u001b[0m\u001b[2m==5.9.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mmatplotlib\u001b[0m\u001b[2m==3.8.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmatplotlib\u001b[0m\u001b[2m==3.10.7\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mmatplotlib-inline\u001b[0m\u001b[2m==0.2.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnest-asyncio\u001b[0m\u001b[2m==1.6.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==1.26.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.3.5\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mparso\u001b[0m\u001b[2m==0.8.5\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpexpect\u001b[0m\u001b[2m==4.9.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpip\u001b[0m\u001b[2m==25.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mplatformdirs\u001b[0m\u001b[2m==4.5.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mprompt-toolkit\u001b[0m\u001b[2m==3.0.52\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mptyprocess\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpure-eval\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpygments\u001b[0m\u001b[2m==2.19.2\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpyzmq\u001b[0m\u001b[2m==27.1.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mseaborn\u001b[0m\u001b[2m==0.13.2\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mstack-data\u001b[0m\u001b[2m==0.6.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mtornado\u001b[0m\u001b[2m==6.5.2\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mtraitlets\u001b[0m\u001b[2m==5.14.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mwcwidth\u001b[0m\u001b[2m==0.2.14\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mwheel\u001b[0m\u001b[2m==0.45.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv sync"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Environment ===\n",
      "Platform: Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.31\n",
      "Python: 3.12.11\n",
      "\n",
      "=== PyTorch / CUDA Info ===\n",
      "torch.__version__: 2.9.1+cu128\n",
      "torch.version.cuda: 12.8\n",
      "torch.cuda.is_available(): True\n",
      "torch.cuda.device_count(): 1\n",
      "  device 0: NVIDIA GeForce RTX 5080\n",
      "\n",
      "=== PyTorch / CUDA Info ===\n",
      "torch.__version__: 2.9.1+cu128\n",
      "torch.version.cuda: 12.8\n",
      "torch.cuda.is_available(): True\n",
      "torch.cuda.device_count(): 1\n",
      "  device 0: NVIDIA GeForce RTX 5080\n",
      "\n",
      "Successfully ran a matrix multiply on CUDA.\n",
      "z.device: cuda:0\n",
      "\n",
      "=== Test Complete ===\n",
      "\n",
      "Successfully ran a matrix multiply on CUDA.\n",
      "z.device: cuda:0\n",
      "\n",
      "=== Test Complete ===\n"
     ]
    }
   ],
   "source": [
    "# save as test_cuda.py and run: python3 test_cuda.py\n",
    "\n",
    "import platform\n",
    "\n",
    "print(\"=== Environment ===\")\n",
    "print(\"Platform:\", platform.platform())\n",
    "print(\"Python:\", platform.python_version())\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "except ImportError as e:\n",
    "    print(\"\\nPyTorch is not installed or not in this Python environment.\")\n",
    "    raise SystemExit(e)\n",
    "\n",
    "print(\"\\n=== PyTorch / CUDA Info ===\")\n",
    "print(\"torch.__version__:\", torch.__version__)\n",
    "print(\"torch.version.cuda:\", torch.version.cuda)\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(\"torch.cuda.is_available():\", cuda_available)\n",
    "\n",
    "if not cuda_available:\n",
    "    print(\"\\nCUDA is NOT available to PyTorch in this environment.\")\n",
    "else:\n",
    "    # Number of devices\n",
    "    device_count = torch.cuda.device_count()\n",
    "    print(\"torch.cuda.device_count():\", device_count)\n",
    "\n",
    "    for i in range(device_count):\n",
    "        print(f\"  device {i}: {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "    # Simple tensor test on GPU\n",
    "    try:\n",
    "        x = torch.rand(3, 3, device=\"cuda\")\n",
    "        y = torch.rand(3, 3, device=\"cuda\")\n",
    "        z = x @ y\n",
    "        print(\"\\nSuccessfully ran a matrix multiply on CUDA.\")\n",
    "        print(\"z.device:\", z.device)\n",
    "    except Exception as e:\n",
    "        print(\"\\nERROR: Allocation or compute on CUDA failed:\")\n",
    "        print(e)\n",
    "\n",
    "print(\"\\n=== Test Complete ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1+cu128\n",
      "12.8\n",
      "91002\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5078345 rows; columns: ['Timestamp', 'From Bank', 'Account', 'To Bank', 'Account.1', 'Amount Received', 'Receiving Currency', 'Amount Paid', 'Payment Currency', 'Payment Format', 'Is Laundering']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>From Bank</th>\n",
       "      <th>Account</th>\n",
       "      <th>To Bank</th>\n",
       "      <th>Account.1</th>\n",
       "      <th>Amount Received</th>\n",
       "      <th>Receiving Currency</th>\n",
       "      <th>Amount Paid</th>\n",
       "      <th>Payment Currency</th>\n",
       "      <th>Payment Format</th>\n",
       "      <th>Is Laundering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022/09/01 00:20</td>\n",
       "      <td>10</td>\n",
       "      <td>8000EBD30</td>\n",
       "      <td>10</td>\n",
       "      <td>8000EBD30</td>\n",
       "      <td>3697.34</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>3697.34</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022/09/01 00:20</td>\n",
       "      <td>3208</td>\n",
       "      <td>8000F4580</td>\n",
       "      <td>1</td>\n",
       "      <td>8000F5340</td>\n",
       "      <td>0.01</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>0.01</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Cheque</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022/09/01 00:00</td>\n",
       "      <td>3209</td>\n",
       "      <td>8000F4670</td>\n",
       "      <td>3209</td>\n",
       "      <td>8000F4670</td>\n",
       "      <td>14675.57</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>14675.57</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022/09/01 00:02</td>\n",
       "      <td>12</td>\n",
       "      <td>8000F5030</td>\n",
       "      <td>12</td>\n",
       "      <td>8000F5030</td>\n",
       "      <td>2806.97</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>2806.97</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022/09/01 00:06</td>\n",
       "      <td>10</td>\n",
       "      <td>8000F5200</td>\n",
       "      <td>10</td>\n",
       "      <td>8000F5200</td>\n",
       "      <td>36682.97</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>36682.97</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
       "0  2022/09/01 00:20         10  8000EBD30       10  8000EBD30   \n",
       "1  2022/09/01 00:20       3208  8000F4580        1  8000F5340   \n",
       "2  2022/09/01 00:00       3209  8000F4670     3209  8000F4670   \n",
       "3  2022/09/01 00:02         12  8000F5030       12  8000F5030   \n",
       "4  2022/09/01 00:06         10  8000F5200       10  8000F5200   \n",
       "\n",
       "   Amount Received Receiving Currency  Amount Paid Payment Currency  \\\n",
       "0          3697.34          US Dollar      3697.34        US Dollar   \n",
       "1             0.01          US Dollar         0.01        US Dollar   \n",
       "2         14675.57          US Dollar     14675.57        US Dollar   \n",
       "3          2806.97          US Dollar      2806.97        US Dollar   \n",
       "4         36682.97          US Dollar     36682.97        US Dollar   \n",
       "\n",
       "  Payment Format  Is Laundering  \n",
       "0   Reinvestment              0  \n",
       "1         Cheque              0  \n",
       "2   Reinvestment              0  \n",
       "3   Reinvestment              0  \n",
       "4   Reinvestment              0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to the small transactions CSV (relative to this notebook).\n",
    "DATA_PATH = Path(\"dataset\") / \"HI-Small_Trans.csv\"\n",
    "\n",
    "# Load into a DataFrame\n",
    "small_trans = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Quick summary and preview\n",
    "print(f\"Loaded {len(small_trans)} rows; columns: {list(small_trans.columns)}\")\n",
    "small_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset loaded: 5078345 edges\n",
      "Fraud edges: 5177, Non-fraud edges: 5073168, base rate 0.001019\n"
     ]
    }
   ],
   "source": [
    "# Use the full transaction table for modeling and keep its imbalance statistics\n",
    "import numpy as np\n",
    "\n",
    "LABEL_COL = 'Is Laundering'\n",
    "RANDOM_SEED = 17\n",
    "\n",
    "working_trans = small_trans.copy().reset_index(drop=True)\n",
    "\n",
    "pos_count = int(working_trans[LABEL_COL].sum())\n",
    "neg_count = len(working_trans) - pos_count\n",
    "fraud_ratio = pos_count / max(len(working_trans), 1)\n",
    "print(f'Full dataset loaded: {len(working_trans)} edges')\n",
    "print(f'Fraud edges: {pos_count}, Non-fraud edges: {neg_count}, base rate {fraud_ratio:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imbalance Visualization Overview (IBM AML Dataset)\n",
    "\n",
    "This section adds visual summaries of the strong class imbalance (fraud vs non‑fraud) and related distributions. Run in order after the dataset has been loaded into `small_trans`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "OVERALL LABEL DISTRIBUTION\n",
      "========================================================================\n",
      "Non-fraud (0)  : 5073168 (99.898%)\n",
      "Fraud (1)      :    5177 ( 0.102%)\n",
      "Fraud ratio overall: 0.00102\n",
      "\n",
      "========================================================================\n",
      "NUMERIC AMOUNT SUMMARY PER CLASS\n",
      "========================================================================\n",
      "Column: Amount Received\n",
      "                 count          mean   median           std     min           max\n",
      "Is Laundering                                                                    \n",
      "0              5073168  5.957962e+06  1407.51  1.036563e+09  0.0000  1.046302e+12\n",
      "1                 5177  3.613531e+07  8667.21  1.527919e+09  0.0032  8.485314e+10\n",
      "----------------------------------------\n",
      "Column: Amount Paid\n",
      "                 count          mean   median           std     min           max\n",
      "Is Laundering                                                                    \n",
      "0              5073168  4.477000e+06  1410.99  8.688463e+08  0.0000  1.046302e+12\n",
      "1                 5177  3.613531e+07  8667.21  1.527919e+09  0.0032  8.485314e+10\n",
      "----------------------------------------\n",
      "\n",
      "========================================================================\n",
      "TEMPORAL FRAUD RATES (first 10 windows)\n",
      "========================================================================\n",
      "Column: Amount Received\n",
      "                 count          mean   median           std     min           max\n",
      "Is Laundering                                                                    \n",
      "0              5073168  5.957962e+06  1407.51  1.036563e+09  0.0000  1.046302e+12\n",
      "1                 5177  3.613531e+07  8667.21  1.527919e+09  0.0032  8.485314e+10\n",
      "----------------------------------------\n",
      "Column: Amount Paid\n",
      "                 count          mean   median           std     min           max\n",
      "Is Laundering                                                                    \n",
      "0              5073168  4.477000e+06  1410.99  8.688463e+08  0.0000  1.046302e+12\n",
      "1                 5177  3.613531e+07  8667.21  1.527919e+09  0.0032  8.485314e+10\n",
      "----------------------------------------\n",
      "\n",
      "========================================================================\n",
      "TEMPORAL FRAUD RATES (first 10 windows)\n",
      "========================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6956/451852787.py:48: FutureWarning: DataFrameGroupBy.resample operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  counts = temp_df.set_index('ts').groupby('label').resample(freq).size().unstack(0).fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using frequency: D\n",
      "            label_0  label_1    total  fraud_rate\n",
      "ts                                               \n",
      "2022-09-01  1114599      322  1114921      0.0003\n",
      "2022-09-02   754041      408   754449      0.0005\n",
      "2022-09-03   206991      391   207382      0.0019\n",
      "2022-09-04   207023      407   207430      0.0020\n",
      "2022-09-05   482179      471   482650      0.0010\n",
      "2022-09-06   481558      531   482089      0.0011\n",
      "2022-09-07   482254      497   482751      0.0010\n",
      "2022-09-08   482234      539   482773      0.0011\n",
      "2022-09-09   653953      514   654467      0.0008\n",
      "2022-09-10   207883      442   208325      0.0021\n",
      "\n",
      "========================================================================\n",
      "ACCOUNT PARTICIPATION SNAPSHOT (top 10)\n",
      "========================================================================\n",
      "Top senders by volume (From Bank):\n",
      "From Bank\n",
      "70     449859\n",
      "10      81629\n",
      "12      79754\n",
      "1       62211\n",
      "15      52511\n",
      "220     52417\n",
      "20      41008\n",
      "3       38413\n",
      "7       31086\n",
      "211     30451\n",
      "\n",
      "Top receivers by volume (To Bank):\n",
      "To Bank\n",
      "10     42547\n",
      "12     41872\n",
      "15     38721\n",
      "220    30625\n",
      "1      30115\n",
      "3      25627\n",
      "7      23029\n",
      "20     22048\n",
      "28     21160\n",
      "211    20576\n",
      "\n",
      "Top senders by fraud count:\n",
      "From Bank\n",
      "70     633\n",
      "12      76\n",
      "20      67\n",
      "119     59\n",
      "10      51\n",
      "1       50\n",
      "11      47\n",
      "15      46\n",
      "22      40\n",
      "118     36\n",
      "\n",
      "Top receivers by fraud count:\n",
      "To Bank\n",
      "12     89\n",
      "119    73\n",
      "11     68\n",
      "20     54\n",
      "1      53\n",
      "10     51\n",
      "22     48\n",
      "222    47\n",
      "23     43\n",
      "15     42\n",
      "\n",
      "\n",
      "========================================================================\n",
      "NUMERIC FEATURE CORRELATIONS WITH FRAUD (top 15 abs(r))\n",
      "========================================================================\n",
      "Top senders by volume (From Bank):\n",
      "From Bank\n",
      "70     449859\n",
      "10      81629\n",
      "12      79754\n",
      "1       62211\n",
      "15      52511\n",
      "220     52417\n",
      "20      41008\n",
      "3       38413\n",
      "7       31086\n",
      "211     30451\n",
      "\n",
      "Top receivers by volume (To Bank):\n",
      "To Bank\n",
      "10     42547\n",
      "12     41872\n",
      "15     38721\n",
      "220    30625\n",
      "1      30115\n",
      "3      25627\n",
      "7      23029\n",
      "20     22048\n",
      "28     21160\n",
      "211    20576\n",
      "\n",
      "Top senders by fraud count:\n",
      "From Bank\n",
      "70     633\n",
      "12      76\n",
      "20      67\n",
      "119     59\n",
      "10      51\n",
      "1       50\n",
      "11      47\n",
      "15      46\n",
      "22      40\n",
      "118     36\n",
      "\n",
      "Top receivers by fraud count:\n",
      "To Bank\n",
      "12     89\n",
      "119    73\n",
      "11     68\n",
      "20     54\n",
      "1      53\n",
      "10     51\n",
      "22     48\n",
      "222    47\n",
      "23     43\n",
      "15     42\n",
      "\n",
      "\n",
      "========================================================================\n",
      "NUMERIC FEATURE CORRELATIONS WITH FRAUD (top 15 abs(r))\n",
      "========================================================================\n",
      "        feature        r  p_value\n",
      "        To Bank -0.00572  0.00000\n",
      "    Amount Paid  0.00116  0.00886\n",
      "Amount Received  0.00093  0.03640\n",
      "      From Bank -0.00023  0.60350\n",
      "        feature        r  p_value\n",
      "        To Bank -0.00572  0.00000\n",
      "    Amount Paid  0.00116  0.00886\n",
      "Amount Received  0.00093  0.03640\n",
      "      From Bank -0.00023  0.60350\n"
     ]
    }
   ],
   "source": [
    "# Text-based imbalance summary for IBM AML dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy.stats import pointbiserialr\n",
    "\n",
    "assert 'working_trans' in globals(), \"Run the balanced sampling cell to create 'working_trans'.\"\n",
    "df = working_trans.copy()\n",
    "label_col = 'Is Laundering'\n",
    "if label_col not in df.columns:\n",
    "    raise KeyError(f\"Expected column '{label_col}' in the dataset.\")\n",
    "\n",
    "print('=' * 72)\n",
    "print('OVERALL LABEL DISTRIBUTION')\n",
    "print('=' * 72)\n",
    "label_counts = df[label_col].value_counts().sort_index()\n",
    "total = label_counts.sum()\n",
    "for label, count in label_counts.items():\n",
    "    pct = 100.0 * count / total\n",
    "    label_name = 'Fraud (1)' if label == 1 else 'Non-fraud (0)'\n",
    "    print(f\"{label_name:<15}: {count:>7} ({pct:6.3f}%)\")\n",
    "fraud_ratio = label_counts.get(1, 0) / max(total, 1)\n",
    "print(f\"Fraud ratio overall: {fraud_ratio:.5f}\")\n",
    "\n",
    "print('\\n' + '=' * 72)\n",
    "print('NUMERIC AMOUNT SUMMARY PER CLASS')\n",
    "print('=' * 72)\n",
    "amount_cols = [c for c in df.columns if any(k in c.lower() for k in ('amount', 'amt', 'value'))]\n",
    "if amount_cols:\n",
    "    for col in amount_cols:\n",
    "        series = pd.to_numeric(df[col], errors='coerce')\n",
    "        summary = df.groupby(label_col)[col].agg(['count', 'mean', 'median', 'std', 'min', 'max'])\n",
    "        print(f\"Column: {col}\")\n",
    "        print(summary.fillna(0).round(4).to_string())\n",
    "        print('-' * 40)\n",
    "else:\n",
    "    print('No amount-like columns detected for summary.')\n",
    "\n",
    "print('\\n' + '=' * 72)\n",
    "print('TEMPORAL FRAUD RATES (first 10 windows)')\n",
    "print('=' * 72)\n",
    "time_col = next((c for c in df.columns if any(k in c.lower() for k in ('time', 'date', 'timestamp'))), None)\n",
    "if time_col:\n",
    "    ts = pd.to_datetime(df[time_col], errors='coerce')\n",
    "    temp_df = pd.DataFrame({'ts': ts, 'label': df[label_col]}).dropna(subset=['ts'])\n",
    "    span_days = (temp_df['ts'].max() - temp_df['ts'].min()).days\n",
    "    freq = 'D' if span_days >= 2 else 'H'\n",
    "    counts = temp_df.set_index('ts').groupby('label').resample(freq).size().unstack(0).fillna(0)\n",
    "    counts.columns = [f'label_{c}' for c in counts.columns]\n",
    "    counts['total'] = counts.sum(axis=1)\n",
    "    counts['fraud_rate'] = counts.get('label_1', 0) / counts['total'].replace(0, np.nan)\n",
    "    print(f\"Using frequency: {freq}\")\n",
    "    preview = counts[['label_0', 'label_1', 'total', 'fraud_rate']].head(10).fillna(0)\n",
    "    print(preview.round({'fraud_rate': 4}).to_string())\n",
    "else:\n",
    "    print('No timestamp/date column detected for temporal summary.')\n",
    "\n",
    "print('\\n' + '=' * 72)\n",
    "print('ACCOUNT PARTICIPATION SNAPSHOT (top 10)')\n",
    "print('=' * 72)\n",
    "sender_col = next((c for c in df.columns if any(k in c.lower() for k in ('sender', 'originator', 'from', 'account'))), None)\n",
    "receiver_col = next((c for c in df.columns if any(k in c.lower() for k in ('receiver', 'beneficiary', 'to', 'account.1', 'account_1'))), None)\n",
    "if sender_col and receiver_col:\n",
    "    part_df = df[[sender_col, receiver_col, label_col]].copy()\n",
    "    top_senders = part_df.groupby(sender_col).size().sort_values(ascending=False).head(10)\n",
    "    top_receivers = part_df.groupby(receiver_col).size().sort_values(ascending=False).head(10)\n",
    "    fraud_senders = part_df.groupby(sender_col)[label_col].sum().sort_values(ascending=False).head(10)\n",
    "    fraud_receivers = part_df.groupby(receiver_col)[label_col].sum().sort_values(ascending=False).head(10)\n",
    "    print(f\"Top senders by volume ({sender_col}):\\n{top_senders.to_string()}\\n\")\n",
    "    print(f\"Top receivers by volume ({receiver_col}):\\n{top_receivers.to_string()}\\n\")\n",
    "    print(f\"Top senders by fraud count:\\n{fraud_senders.to_string()}\\n\")\n",
    "    print(f\"Top receivers by fraud count:\\n{fraud_receivers.to_string()}\\n\")\n",
    "else:\n",
    "    print('Could not identify sender/receiver columns for participation snapshot.')\n",
    "\n",
    "print('\\n' + '=' * 72)\n",
    "print('NUMERIC FEATURE CORRELATIONS WITH FRAUD (top 15 abs(r))')\n",
    "print('=' * 72)\n",
    "num_cols = [c for c in df.select_dtypes(include=[np.number]).columns if c != label_col]\n",
    "if num_cols:\n",
    "    corrs = []\n",
    "    y = df[label_col].values\n",
    "    for c in num_cols:\n",
    "        x = pd.to_numeric(df[c], errors='coerce').fillna(0).values\n",
    "        try:\n",
    "            r, p = pointbiserialr(y, x)\n",
    "        except Exception:\n",
    "            r, p = np.nan, np.nan\n",
    "        corrs.append({'feature': c, 'r': r, 'p_value': p})\n",
    "    corr_df = pd.DataFrame(corrs)\n",
    "    corr_df['abs_r'] = corr_df['r'].abs()\n",
    "    corr_df = corr_df.sort_values(by='abs_r', ascending=False).head(15)\n",
    "    print(corr_df[['feature', 'r', 'p_value']].round(5).to_string(index=False))\n",
    "else:\n",
    "    print('No numeric columns (besides label) available for correlation analysis.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# convert hex account numbers to int\n",
    "hex_to_int = np.vectorize(lambda x: int(x, 16))\n",
    "\n",
    "# create adjacency lists to represent the graph\n",
    "source = hex_to_int(working_trans['Account'])\n",
    "target = hex_to_int(working_trans['Account.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/SFSU/CSC871/csc865-anti-money-laundering-ibm/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_nodes: 515080 num_edges: 5078345\n",
      "Data(edge_index=[2, 5078345], num_nodes=515080)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "\n",
    "# Map account IDs to a compact 0..N-1 index space to avoid huge sparse IDs\n",
    "# Concatenate unique accounts from source/target and factorize\n",
    "all_accounts = np.concatenate([source, target])\n",
    "unique_accounts, inverse_idx = np.unique(all_accounts, return_inverse=True)\n",
    "num_nodes = unique_accounts.shape[0]\n",
    "# Rebuild source/target as compact indices\n",
    "source_idx = inverse_idx[:source.shape[0]]\n",
    "target_idx = inverse_idx[source.shape[0]:]\n",
    "\n",
    "# Build edge_index\n",
    "edge_index = torch.tensor(np.vstack([source_idx, target_idx]), dtype=torch.long)\n",
    "\n",
    "# Create Data object\n",
    "data = Data(edge_index=edge_index, num_nodes=num_nodes)\n",
    "print('num_nodes:', num_nodes, 'num_edges:', edge_index.size(1))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 5078345], num_nodes=515080, edge_attr=[5078345, 3], edge_label=[5078345])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "\n",
    "# extract individual edge features\n",
    "time = pd.to_datetime(working_trans['Timestamp']).astype('int64') / 1e9\n",
    "amount_paid = working_trans['Amount Paid'].to_numpy()\n",
    "amount_received = working_trans['Amount Received'].to_numpy()\n",
    "\n",
    "# combine edge features into single tensor (standardised numeric block)\n",
    "numeric_features = np.column_stack([time, amount_paid, amount_received])\n",
    "scaler = StandardScaler()\n",
    "numeric_scaled = scaler.fit_transform(numeric_features)\n",
    "edge_features = torch.from_numpy(numeric_scaled).float()\n",
    "\n",
    "# create edge labels\n",
    "fraud_label = torch.tensor(working_trans['Is Laundering'].to_numpy(), dtype=torch.long)\n",
    "\n",
    "# attach features and labels to PyG Data\n",
    "data.edge_attr = edge_features\n",
    "data.edge_label = fraud_label\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "\n",
    "# Increase edge_batch_size if you have ample memory and want fewer edge chunks per epoch.\n",
    "edge_batch_size = 1024\n",
    "# Toggle GPU usage; set to False to keep everything on CPU even if CUDA is visible.\n",
    "use_gpu = torch.cuda.is_available()\n",
    "# Ratio of sampled negatives to each positive edge during fallback training.\n",
    "neg_pos_ratio = 10.0\n",
    "# Scale factor applied to the empirical class imbalance when computing pos_weight.\n",
    "pos_weight_scale = 0.2\n",
    "# Optional manual override for pos_weight (set to a float to force a value).\n",
    "pos_weight_override = None\n",
    "# Number of epochs to train for.\n",
    "epochs = 20\n",
    "# Hidden dimension for the GNN and edge classifier.\n",
    "num_hid = 64\n",
    "# Smaller learning rate to keep updates stable on imbalanced data.\n",
    "learn_rate = 5e-4\n",
    "# Weight decay for the optimizer.\n",
    "decay = 1e-4\n",
    "# Gradient clipping threshold (set <=0 to disable).\n",
    "grad_clip = 1.0\n",
    "# False positive rate target used when calibrating the decision threshold on validation data.\n",
    "fpr_target = 0.05\n",
    "# Minimum epochs before enabling regular recalibration so the loss can settle.\n",
    "calibrate_warmup = 6\n",
    "# How often (in epochs) to re-fit the validation ROC and refresh the threshold after warmup.\n",
    "calibrate_every = 3\n",
    "# Blend factor applied when updating the threshold (0=no change, 1=replace).\n",
    "threshold_blend = 0.25\n",
    "# Hard floor on the decision threshold to avoid runaway false positives.\n",
    "threshold_floor = 0.4\n",
    "# Hard ceiling on the decision threshold for numerical safety.\n",
    "threshold_ceiling = 0.99\n",
    "# Maximum allowed validation positive fraction before skipping a threshold update.\n",
    "max_val_pos_frac = 0.35\n",
    "# Maximum allowed validation FPR before skipping a threshold update.\n",
    "max_val_fpr = 0.2\n",
    "# Maximum allowed FPR on a raw-distribution sample when updating thresholds.\n",
    "max_full_sample_fpr = 0.05\n",
    "# Number of raw transactions sampled for full-distribution FPR checks.\n",
    "full_val_sample_size = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw-sample guard set: 20000 edges, fraud ratio 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Build a raw-distribution sample for calibration guardrails\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data as PyGData\n",
    "\n",
    "# Use the same RNG seed to keep sampling deterministic across runs\n",
    "raw_sample_size = min(int(full_val_sample_size), len(small_trans))\n",
    "if raw_sample_size <= 0:\n",
    "    raise ValueError('Dataset is empty; cannot create raw-sample guard for calibration.')\n",
    "raw_sample_idx = np.random.default_rng(RANDOM_SEED).choice(len(small_trans), size=raw_sample_size, replace=False)\n",
    "raw_sample_df = small_trans.iloc[raw_sample_idx].reset_index(drop=True)\n",
    "\n",
    "raw_source = hex_to_int(raw_sample_df['Account'])\n",
    "raw_target = hex_to_int(raw_sample_df['Account.1'])\n",
    "\n",
    "raw_all_accounts = np.concatenate([raw_source, raw_target])\n",
    "raw_unique_accounts, raw_inverse_idx = np.unique(raw_all_accounts, return_inverse=True)\n",
    "raw_num_nodes = raw_unique_accounts.shape[0]\n",
    "raw_source_idx = raw_inverse_idx[:raw_source.shape[0]]\n",
    "raw_target_idx = raw_inverse_idx[raw_source.shape[0]:]\n",
    "\n",
    "raw_edge_index = torch.tensor(np.vstack([raw_source_idx, raw_target_idx]), dtype=torch.long)\n",
    "raw_data = PyGData(edge_index=raw_edge_index, num_nodes=raw_num_nodes)\n",
    "\n",
    "raw_deg = torch.zeros((raw_num_nodes, 1), dtype=torch.float)\n",
    "raw_deg.scatter_add_(0, raw_edge_index[0].view(-1, 1), torch.ones((raw_edge_index.size(1), 1)))\n",
    "raw_data.x = raw_deg\n",
    "\n",
    "raw_time = pd.to_datetime(raw_sample_df['Timestamp']).astype('int64') / 1e9\n",
    "raw_amount_paid = raw_sample_df['Amount Paid'].to_numpy()\n",
    "raw_amount_received = raw_sample_df['Amount Received'].to_numpy()\n",
    "raw_numeric = np.column_stack([raw_time, raw_amount_paid, raw_amount_received])\n",
    "raw_numeric_scaled = scaler.transform(raw_numeric)\n",
    "raw_edge_attr = torch.from_numpy(raw_numeric_scaled).float()\n",
    "raw_edge_label = torch.tensor(raw_sample_df[LABEL_COL].to_numpy(), dtype=torch.long)\n",
    "\n",
    "raw_data.edge_attr = raw_edge_attr\n",
    "raw_data.edge_label = raw_edge_label\n",
    "\n",
    "print(f'Raw-sample guard set: {raw_sample_size} edges, fraud ratio {raw_edge_label.float().mean().item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masks set: 3047007 1015669 1015669\n",
      "Train positive ratio: 0.001019360963255167\n",
      "Val positive ratio: 0.0010190327884629369\n",
      "Test positive ratio: 0.0010200173128396273\n"
     ]
    }
   ],
   "source": [
    "# Stratified 60/20/20 split to keep the raw class imbalance in each subset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "num_edges = data.edge_index.size(1)\n",
    "all_indices = np.arange(num_edges)\n",
    "labels_np = data.edge_label.cpu().numpy()\n",
    "\n",
    "train_idx, temp_idx = train_test_split(\n",
    "    all_indices,\n",
    "    test_size=0.4,\n",
    "    stratify=labels_np,\n",
    "    random_state=RANDOM_SEED,\n",
    "    shuffle=True,\n",
    "    )\n",
    "\n",
    "val_idx, test_idx = train_test_split(\n",
    "    temp_idx,\n",
    "    test_size=0.5,\n",
    "    stratify=labels_np[temp_idx],\n",
    "    random_state=RANDOM_SEED,\n",
    "    shuffle=True,\n",
    "    )\n",
    "\n",
    "train_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
    "val_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
    "\n",
    "train_mask[torch.from_numpy(train_idx)] = True\n",
    "val_mask[torch.from_numpy(val_idx)] = True\n",
    "test_mask[torch.from_numpy(test_idx)] = True\n",
    "\n",
    "data.train_mask = train_mask\n",
    "data.val_mask = val_mask\n",
    "data.test_mask = test_mask\n",
    "\n",
    "print('Masks set:', train_mask.sum().item(), val_mask.sum().item(), test_mask.sum().item())\n",
    "print('Train positive ratio:', data.edge_label[train_mask].float().mean().item())\n",
    "print('Val positive ratio:', data.edge_label[val_mask].float().mean().item())\n",
    "print('Test positive ratio:', data.edge_label[test_mask].float().mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PyG GNN model and edge classification training (batched)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import TransformerConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Ensure data object exists with edge_index, edge_attr, edge_label, and masks\n",
    "assert data is not None, 'PyG Data not constructed yet'\n",
    "num_nodes = data.num_nodes\n",
    "num_edges = data.edge_index.size(1)\n",
    "if getattr(data, 'edge_attr', None) is None:\n",
    "    raise RuntimeError('Edge features missing. Run Cell 12 (edge feature construction) before this cell.')\n",
    "edge_feat_dim = data.edge_attr.size(1)\n",
    "\n",
    "# Create simple node features if none exist (e.g., degree or identity)\n",
    "if getattr(data, 'x', None) is None:\n",
    "    deg = torch.zeros((num_nodes, 1), dtype=torch.float)\n",
    "    deg.scatter_add_(0, data.edge_index[0].view(-1,1), torch.ones((num_edges,1)))\n",
    "    data.x = deg  # use degree as a simple node feature\n",
    "\n",
    "class GNN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, edge_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = TransformerConv(in_channels, hidden_channels, edge_dim=edge_dim)\n",
    "        self.conv2 = TransformerConv(hidden_channels, hidden_channels, edge_dim=edge_dim)\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = self.conv1(x, edge_index, edge_attr=edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index, edge_attr=edge_attr)\n",
    "        return x\n",
    "\n",
    "class EdgeClassifier(nn.Module):\n",
    "    def __init__(self, node_hidden, edge_feat_dim, hidden=num_hid):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(node_hidden*2 + edge_feat_dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, 1)\n",
    "        )\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        u, v = edge_index\n",
    "        h = torch.cat([x[u], x[v], edge_attr], dim=1)\n",
    "        return self.mlp(h).squeeze(-1)\n",
    "    def score_pairs(self, x, u, v, edge_attr):\n",
    "        h = torch.cat([x[u], x[v], edge_attr], dim=1)\n",
    "        return self.mlp(h).squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbor sampling backend missing: install 'pyg-lib' (preferred) or 'torch-sparse'.\n",
      "Suggested install command (run in a terminal):\n",
      "/mnt/d/SFSU/CSC871/csc865-anti-money-laundering-ibm/.venv/bin/python -m pip install pyg-lib torch-sparse -f https://data.pyg.org/whl/torch-2.9.1+cu128.html\n",
      "Fallback to full-graph edge training will be used until a backend is installed.\n",
      "Note: pyg_lib currently does not support some newer PyTorch versions; fallback will be used if install fails.\n",
      "Using GPU device: NVIDIA GeForce RTX 5080 (index 0).\n",
      "Train edges: 3047007 | positives: 3106 (0.001019) | pos_weight 490.00 | neg/pos ratio target 2.0:1\n",
      "Fallback mode active on CUDA device: full-graph embeddings with edge chunks of 1024 (train edges 3047007, val 1015669, test 1015669).\n",
      "edge_batch_size controls chunking in this mode; install pyg-lib or torch-sparse to enable true neighbor sampling.\n",
      "Train edges: 3047007 | positives: 3106 (0.001019) | pos_weight 490.00 | neg/pos ratio target 2.0:1\n",
      "Fallback mode active on CUDA device: full-graph embeddings with edge chunks of 1024 (train edges 3047007, val 1015669, test 1015669).\n",
      "edge_batch_size controls chunking in this mode; install pyg-lib or torch-sparse to enable true neighbor sampling.\n"
     ]
    }
   ],
   "source": [
    "import importlib, math, torch, sys, subprocess, os\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "# Detect if neighbor sampling backend (pyg_lib or torch_sparse) is available\n",
    "backend_ok = bool(importlib.util.find_spec(\"pyg_lib\") or importlib.util.find_spec(\"torch_sparse\"))\n",
    "fallback_splits = {}\n",
    "if not backend_ok:\n",
    "    print(\"Neighbor sampling backend missing: install 'pyg-lib' (preferred) or 'torch-sparse'.\")\n",
    "    torch_ver = torch.__version__.split('+')[0]\n",
    "    cuda_ver = torch.version.cuda\n",
    "    if cuda_ver is None:\n",
    "        cuda_tag = 'cpu'\n",
    "    else:\n",
    "        cuda_tag = 'cu' + cuda_ver.replace('.', '')\n",
    "    index_url = f'https://data.pyg.org/whl/torch-{torch_ver}+{cuda_tag}.html'\n",
    "    print('Suggested install command (run in a terminal):')\n",
    "    print(f\"{sys.executable} -m pip install pyg-lib torch-sparse -f {index_url}\")\n",
    "    print('Fallback to full-graph edge training will be used until a backend is installed.')\n",
    "    print('Note: pyg_lib currently does not support some newer PyTorch versions; fallback will be used if install fails.')\n",
    "\n",
    "requested_gpu = use_gpu and torch.cuda.is_available()\n",
    "device = torch.device('cuda') if requested_gpu else torch.device('cpu')\n",
    "if device.type == 'cuda':\n",
    "    dev_index = device.index if device.index is not None else torch.cuda.current_device()\n",
    "    print(f'Using GPU device: {torch.cuda.get_device_name(dev_index)} (index {dev_index}).')\n",
    "else:\n",
    "    if use_gpu and not torch.cuda.is_available():\n",
    "        print('CUDA requested but not available; falling back to CPU.')\n",
    "    else:\n",
    "        print('Using CPU for training (set use_gpu=True and ensure CUDA availability to use GPU).')\n",
    "\n",
    "gnn = GNN(in_channels=data.x.size(1), hidden_channels=num_hid, edge_dim=edge_feat_dim).to(device)\n",
    "clf = EdgeClassifier(node_hidden=num_hid, edge_feat_dim=edge_feat_dim, hidden=num_hid*2).to(device)\n",
    "\n",
    "params = list(gnn.parameters()) + list(clf.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr=learn_rate, weight_decay=decay)\n",
    "\n",
    "# Build edge_label_index and edge_label tensors for each split\n",
    "train_edge_label_index = data.edge_index[:, data.train_mask]\n",
    "train_edge_label = data.edge_label[data.train_mask]\n",
    "\n",
    "val_edge_label_index = data.edge_index[:, data.val_mask]\n",
    "val_edge_label = data.edge_label[data.val_mask]\n",
    "\n",
    "test_edge_label_index = data.edge_index[:, data.test_mask]\n",
    "test_edge_label = data.edge_label[data.test_mask]\n",
    "\n",
    "train_pos = int(train_edge_label.sum().item())\n",
    "train_total = int(train_edge_label.numel())\n",
    "train_neg = max(train_total - train_pos, 0)\n",
    "base_pos_weight = (train_neg / max(train_pos, 1)) if train_pos > 0 else 1.0\n",
    "if pos_weight_override is not None:\n",
    "    pos_weight_value = float(pos_weight_override)\n",
    "else:\n",
    "    pos_weight_value = max(base_pos_weight * pos_weight_scale, 1.0)\n",
    "pos_weight_tensor = torch.tensor(pos_weight_value, dtype=torch.float, device=device)\n",
    "print(f'Train edges: {train_total} | positives: {train_pos} ({train_pos / max(train_total,1):.6f}) | pos_weight {pos_weight_value:.2f} | neg/pos ratio target {neg_pos_ratio:.1f}:1')\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n",
    "\n",
    "# Safer defaults for batch size & neighbors to reduce per-batch time/memory\n",
    "batch_size = edge_batch_size  # configurable via hyperparameter cell\n",
    "num_neighbors = [10, 5]  # fewer neighbors for smaller subgraphs\n",
    "\n",
    "fallback_mode = not backend_ok\n",
    "if backend_ok:\n",
    "    print(f'Backend OK: {backend_ok} | batch_size: {batch_size} | num_neighbors: {num_neighbors}')\n",
    "    train_loader = LinkNeighborLoader(\n",
    "        data,\n",
    "        num_neighbors=num_neighbors,\n",
    "        batch_size=batch_size,\n",
    "        edge_label_index=train_edge_label_index,\n",
    "        edge_label=train_edge_label,\n",
    "        shuffle=True,\n",
    "        neg_sampling_ratio=0.0\n",
    "    )\n",
    "    val_loader = LinkNeighborLoader(\n",
    "        data,\n",
    "        num_neighbors=num_neighbors,\n",
    "        batch_size=batch_size,\n",
    "        edge_label_index=val_edge_label_index,\n",
    "        edge_label=val_edge_label,\n",
    "        shuffle=False,\n",
    "        neg_sampling_ratio=0.0\n",
    "    )\n",
    "    test_loader = LinkNeighborLoader(\n",
    "        data,\n",
    "        num_neighbors=num_neighbors,\n",
    "        batch_size=batch_size,\n",
    "        edge_label_index=test_edge_label_index,\n",
    "        edge_label=test_edge_label,\n",
    "        shuffle=False,\n",
    "        neg_sampling_ratio=0.0\n",
    "    )\n",
    "else:\n",
    "    def _split_edges(mask):\n",
    "        return {\n",
    "            'edge_label_index': data.edge_index[:, mask],\n",
    "            'edge_label': data.edge_label[mask],\n",
    "            'edge_attr': data.edge_attr[mask]\n",
    "        }\n",
    "    fallback_splits = {\n",
    "        'train': _split_edges(data.train_mask),\n",
    "        'val': _split_edges(data.val_mask),\n",
    "        'test': _split_edges(data.test_mask)\n",
    "    }\n",
    "    train_loader = fallback_splits['train']\n",
    "    val_loader = fallback_splits['val']\n",
    "    test_loader = fallback_splits['test']\n",
    "    train_count = fallback_splits['train']['edge_label'].numel()\n",
    "    val_count = fallback_splits['val']['edge_label'].numel()\n",
    "    test_count = fallback_splits['test']['edge_label'].numel()\n",
    "    chunk_size = max(int(edge_batch_size), 1)\n",
    "    print(f'Fallback mode active on {device.type.upper()} device: full-graph embeddings with edge chunks of {chunk_size} (train edges {train_count}, val {val_count}, test {test_count}).')\n",
    "    print('edge_batch_size controls chunking in this mode; install pyg-lib or torch-sparse to enable true neighbor sampling.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  raw-sample threshold raised from 0.6144 to 0.9500 to respect FPR <= 0.120\n",
      "  raw-sample metrics -> precision 0.000, recall 0.000, fpr 0.0007\n",
      "Epoch 01 | loss 168639.8281 | time 1.4s | train_acc 0.887 | val_acc 0.950 | val_precision 0.002 | val_recall 0.109 | val_f1 0.004 | val_fpr 0.0490 | val_thresh 0.9500 | val_pos_frac 0.04902\n",
      "Epoch 02 | loss 58191.8047 | time 0.4s | train_acc 0.829 | val_acc 0.829 | val_precision 0.001 | val_recall 0.172 | val_f1 0.002 | val_fpr 0.1702 | val_thresh 0.9500 | val_pos_frac 0.17017\n",
      "Epoch 02 | loss 58191.8047 | time 0.4s | train_acc 0.829 | val_acc 0.829 | val_precision 0.001 | val_recall 0.172 | val_f1 0.002 | val_fpr 0.1702 | val_thresh 0.9500 | val_pos_frac 0.17017\n",
      "Epoch 03 | loss 15685.5020 | time 0.4s | train_acc 0.575 | val_acc 0.575 | val_precision 0.001 | val_recall 0.332 | val_f1 0.002 | val_fpr 0.4245 | val_thresh 0.9500 | val_pos_frac 0.42442\n",
      "Epoch 03 | loss 15685.5020 | time 0.4s | train_acc 0.575 | val_acc 0.575 | val_precision 0.001 | val_recall 0.332 | val_f1 0.002 | val_fpr 0.4245 | val_thresh 0.9500 | val_pos_frac 0.42442\n",
      "Epoch 04 | loss 2233.0176 | time 0.3s | train_acc 0.337 | val_acc 0.337 | val_precision 0.001 | val_recall 0.503 | val_f1 0.002 | val_fpr 0.6629 | val_thresh 0.9500 | val_pos_frac 0.66277\n",
      "Epoch 04 | loss 2233.0176 | time 0.3s | train_acc 0.337 | val_acc 0.337 | val_precision 0.001 | val_recall 0.503 | val_f1 0.002 | val_fpr 0.6629 | val_thresh 0.9500 | val_pos_frac 0.66277\n",
      "Epoch 05 | loss 789.8277 | time 0.3s | train_acc 0.226 | val_acc 0.226 | val_precision 0.001 | val_recall 0.632 | val_f1 0.002 | val_fpr 0.7741 | val_thresh 0.9500 | val_pos_frac 0.77398\n",
      "Epoch 05 | loss 789.8277 | time 0.3s | train_acc 0.226 | val_acc 0.226 | val_precision 0.001 | val_recall 0.632 | val_f1 0.002 | val_fpr 0.7741 | val_thresh 0.9500 | val_pos_frac 0.77398\n",
      "  skip threshold update: val_fpr 0.271 exceeds 0.250\n",
      "Epoch 06 | loss 986.8834 | time 0.3s | train_acc 0.203 | val_acc 0.729 | val_precision 0.001 | val_recall 0.273 | val_f1 0.002 | val_fpr 0.2710 | val_thresh 0.9500 | val_pos_frac 0.27100\n",
      "  skip threshold update: val_fpr 0.271 exceeds 0.250\n",
      "Epoch 06 | loss 986.8834 | time 0.3s | train_acc 0.203 | val_acc 0.729 | val_precision 0.001 | val_recall 0.273 | val_f1 0.002 | val_fpr 0.2710 | val_thresh 0.9500 | val_pos_frac 0.27100\n",
      "Epoch 07 | loss 935.1926 | time 0.3s | train_acc 0.224 | val_acc 0.224 | val_precision 0.001 | val_recall 0.641 | val_f1 0.002 | val_fpr 0.7766 | val_thresh 0.9500 | val_pos_frac 0.77645\n",
      "Epoch 07 | loss 935.1926 | time 0.3s | train_acc 0.224 | val_acc 0.224 | val_precision 0.001 | val_recall 0.641 | val_f1 0.002 | val_fpr 0.7766 | val_thresh 0.9500 | val_pos_frac 0.77645\n",
      "Epoch 08 | loss 964.7656 | time 0.3s | train_acc 0.304 | val_acc 0.304 | val_precision 0.001 | val_recall 0.570 | val_f1 0.002 | val_fpr 0.6960 | val_thresh 0.9500 | val_pos_frac 0.69583\n",
      "Epoch 08 | loss 964.7656 | time 0.3s | train_acc 0.304 | val_acc 0.304 | val_precision 0.001 | val_recall 0.570 | val_f1 0.002 | val_fpr 0.6960 | val_thresh 0.9500 | val_pos_frac 0.69583\n",
      "  raw-sample metrics -> precision 0.002, recall 0.158, fpr 0.0852\n",
      "Epoch 09 | loss 865.7599 | time 0.3s | train_acc 0.389 | val_acc 0.816 | val_precision 0.001 | val_recall 0.218 | val_f1 0.002 | val_fpr 0.1830 | val_thresh 0.9500 | val_pos_frac 0.18302\n",
      "  raw-sample metrics -> precision 0.002, recall 0.158, fpr 0.0852\n",
      "Epoch 09 | loss 865.7599 | time 0.3s | train_acc 0.389 | val_acc 0.816 | val_precision 0.001 | val_recall 0.218 | val_f1 0.002 | val_fpr 0.1830 | val_thresh 0.9500 | val_pos_frac 0.18302\n",
      "Epoch 10 | loss 5355.0444 | time 0.3s | train_acc 0.374 | val_acc 0.375 | val_precision 0.001 | val_recall 0.524 | val_f1 0.002 | val_fpr 0.6253 | val_thresh 0.9500 | val_pos_frac 0.62515\n",
      "Epoch 10 | loss 5355.0444 | time 0.3s | train_acc 0.374 | val_acc 0.375 | val_precision 0.001 | val_recall 0.524 | val_f1 0.002 | val_fpr 0.6253 | val_thresh 0.9500 | val_pos_frac 0.62515\n",
      "Epoch 11 | loss 4431.3892 | time 0.3s | train_acc 0.298 | val_acc 0.298 | val_precision 0.001 | val_recall 0.608 | val_f1 0.002 | val_fpr 0.7024 | val_thresh 0.9500 | val_pos_frac 0.70230\n",
      "Epoch 11 | loss 4431.3892 | time 0.3s | train_acc 0.298 | val_acc 0.298 | val_precision 0.001 | val_recall 0.608 | val_f1 0.002 | val_fpr 0.7024 | val_thresh 0.9500 | val_pos_frac 0.70230\n",
      "  skip threshold update: val_fpr 0.255 exceeds 0.250\n",
      "Epoch 12 | loss 779.0370 | time 0.3s | train_acc 0.287 | val_acc 0.745 | val_precision 0.001 | val_recall 0.271 | val_f1 0.002 | val_fpr 0.2547 | val_thresh 0.9500 | val_pos_frac 0.25476\n",
      "  skip threshold update: val_fpr 0.255 exceeds 0.250\n",
      "Epoch 12 | loss 779.0370 | time 0.3s | train_acc 0.287 | val_acc 0.745 | val_precision 0.001 | val_recall 0.271 | val_f1 0.002 | val_fpr 0.2547 | val_thresh 0.9500 | val_pos_frac 0.25476\n",
      "Epoch 13 | loss 709.3737 | time 0.3s | train_acc 0.318 | val_acc 0.318 | val_precision 0.001 | val_recall 0.577 | val_f1 0.002 | val_fpr 0.6819 | val_thresh 0.9500 | val_pos_frac 0.68184\n",
      "Epoch 13 | loss 709.3737 | time 0.3s | train_acc 0.318 | val_acc 0.318 | val_precision 0.001 | val_recall 0.577 | val_f1 0.002 | val_fpr 0.6819 | val_thresh 0.9500 | val_pos_frac 0.68184\n",
      "Epoch 14 | loss 645.6166 | time 0.3s | train_acc 0.399 | val_acc 0.399 | val_precision 0.001 | val_recall 0.526 | val_f1 0.002 | val_fpr 0.6014 | val_thresh 0.9500 | val_pos_frac 0.60129\n",
      "Epoch 14 | loss 645.6166 | time 0.3s | train_acc 0.399 | val_acc 0.399 | val_precision 0.001 | val_recall 0.526 | val_f1 0.002 | val_fpr 0.6014 | val_thresh 0.9500 | val_pos_frac 0.60129\n",
      "  raw-sample metrics -> precision 0.001, recall 0.053, fpr 0.0559\n",
      "Epoch 15 | loss 583.0736 | time 0.3s | train_acc 0.525 | val_acc 0.773 | val_precision 0.001 | val_recall 0.238 | val_f1 0.002 | val_fpr 0.2268 | val_thresh 0.9500 | val_pos_frac 0.22679\n",
      "  raw-sample metrics -> precision 0.001, recall 0.053, fpr 0.0559\n",
      "Epoch 15 | loss 583.0736 | time 0.3s | train_acc 0.525 | val_acc 0.773 | val_precision 0.001 | val_recall 0.238 | val_f1 0.002 | val_fpr 0.2268 | val_thresh 0.9500 | val_pos_frac 0.22679\n",
      "Epoch 16 | loss 410.7609 | time 0.3s | train_acc 0.641 | val_acc 0.640 | val_precision 0.001 | val_recall 0.394 | val_f1 0.002 | val_fpr 0.3593 | val_thresh 0.9500 | val_pos_frac 0.35934\n",
      "Epoch 16 | loss 410.7609 | time 0.3s | train_acc 0.641 | val_acc 0.640 | val_precision 0.001 | val_recall 0.394 | val_f1 0.002 | val_fpr 0.3593 | val_thresh 0.9500 | val_pos_frac 0.35934\n",
      "Epoch 17 | loss 728.6356 | time 0.3s | train_acc 0.683 | val_acc 0.683 | val_precision 0.001 | val_recall 0.352 | val_f1 0.002 | val_fpr 0.3171 | val_thresh 0.9500 | val_pos_frac 0.31713\n",
      "Epoch 17 | loss 728.6356 | time 0.3s | train_acc 0.683 | val_acc 0.683 | val_precision 0.001 | val_recall 0.352 | val_f1 0.002 | val_fpr 0.3171 | val_thresh 0.9500 | val_pos_frac 0.31713\n",
      "  raw-sample metrics -> precision 0.000, recall 0.000, fpr 0.0027\n",
      "Epoch 18 | loss 819.0027 | time 0.3s | train_acc 0.753 | val_acc 0.869 | val_precision 0.001 | val_recall 0.132 | val_f1 0.002 | val_fpr 0.1303 | val_thresh 0.9500 | val_pos_frac 0.13035\n",
      "  raw-sample metrics -> precision 0.000, recall 0.000, fpr 0.0027\n",
      "Epoch 18 | loss 819.0027 | time 0.3s | train_acc 0.753 | val_acc 0.869 | val_precision 0.001 | val_recall 0.132 | val_f1 0.002 | val_fpr 0.1303 | val_thresh 0.9500 | val_pos_frac 0.13035\n",
      "Epoch 19 | loss 5618.4106 | time 0.3s | train_acc 0.783 | val_acc 0.782 | val_precision 0.001 | val_recall 0.200 | val_f1 0.002 | val_fpr 0.2178 | val_thresh 0.9500 | val_pos_frac 0.21775\n",
      "Epoch 19 | loss 5618.4106 | time 0.3s | train_acc 0.783 | val_acc 0.782 | val_precision 0.001 | val_recall 0.200 | val_f1 0.002 | val_fpr 0.2178 | val_thresh 0.9500 | val_pos_frac 0.21775\n",
      "Epoch 20 | loss 5327.7100 | time 0.4s | train_acc 0.671 | val_acc 0.671 | val_precision 0.001 | val_recall 0.310 | val_f1 0.002 | val_fpr 0.3291 | val_thresh 0.9500 | val_pos_frac 0.32909\n",
      "Epoch 20 | loss 5327.7100 | time 0.4s | train_acc 0.671 | val_acc 0.671 | val_precision 0.001 | val_recall 0.310 | val_f1 0.002 | val_fpr 0.3291 | val_thresh 0.9500 | val_pos_frac 0.32909\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, roc_curve\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import math\n",
    "import gc\n",
    "from contextlib import nullcontext\n",
    "\n",
    "\n",
    "def _gather_label_edge_attr(batch):\n",
    "    # Map local edges (u,v) -> position in batch.edge_index to gather edge_attr for labeled edges\n",
    "    e_u = batch.edge_index[0].tolist()\n",
    "    e_v = batch.edge_index[1].tolist()\n",
    "    pos_map = {(eu, ev): i for i, (eu, ev) in enumerate(zip(e_u, e_v))}\n",
    "    lu = batch.edge_label_index[0].tolist()\n",
    "    lv = batch.edge_label_index[1].tolist()\n",
    "    idx = [pos_map[(u, v)] for u, v in zip(lu, lv)]\n",
    "    return batch.edge_attr[idx]\n",
    "\n",
    "\n",
    "def _iter_fallback_chunks(split, chunk_size, index_subset=None):\n",
    "    edge_index = split['edge_label_index']\n",
    "    edge_attr = split['edge_attr']\n",
    "    edge_label = split['edge_label']\n",
    "    if index_subset is None:\n",
    "        indices = torch.arange(edge_label.size(0))\n",
    "    else:\n",
    "        indices = index_subset\n",
    "    total = indices.numel()\n",
    "    for start in range(0, total, chunk_size):\n",
    "        sel = indices[start:min(start + chunk_size, total)]\n",
    "        yield edge_index[:, sel], edge_attr[sel], edge_label[sel]\n",
    "\n",
    "\n",
    "def _sample_balanced_indices(labels, ratio):\n",
    "    pos_idx = torch.nonzero(labels == 1, as_tuple=False).view(-1)\n",
    "    neg_idx = torch.nonzero(labels == 0, as_tuple=False).view(-1)\n",
    "    if pos_idx.numel() == 0:\n",
    "        return torch.zeros(0, dtype=torch.long)\n",
    "    neg_needed = int(math.ceil(pos_idx.numel() * ratio))\n",
    "    if neg_idx.numel() == 0:\n",
    "        combined = pos_idx\n",
    "    else:\n",
    "        neg_needed = min(max(neg_needed, pos_idx.numel()), neg_idx.numel())\n",
    "        perm = torch.randperm(neg_idx.numel())\n",
    "        sampled_neg = neg_idx[perm[:neg_needed]]\n",
    "        combined = torch.cat([pos_idx, sampled_neg])\n",
    "    shuffle = torch.randperm(combined.numel())\n",
    "    return combined[shuffle]\n",
    "\n",
    "\n",
    "def _select_threshold(y_true, probs, target_fpr=0.02):\n",
    "    if y_true.size == 0:\n",
    "        return 0.5\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, probs)\n",
    "    if np.isnan(thresholds).all():\n",
    "        return 0.5\n",
    "    # Remove infinities for stability\n",
    "    finite_mask = np.isfinite(thresholds)\n",
    "    fpr, tpr, thresholds = fpr[finite_mask], tpr[finite_mask], thresholds[finite_mask]\n",
    "    if thresholds.size == 0:\n",
    "        return 0.5\n",
    "    if target_fpr is not None:\n",
    "        ok = np.where(fpr <= target_fpr)[0]\n",
    "        if ok.size > 0:\n",
    "            idx = ok[np.argmax(tpr[ok])]\n",
    "        else:\n",
    "            idx = np.argmin(fpr)\n",
    "    else:\n",
    "        youden = tpr - fpr\n",
    "        idx = np.argmax(youden)\n",
    "    thr = thresholds[idx]\n",
    "    if np.isnan(thr):\n",
    "        thr = 0.5\n",
    "    return float(np.clip(thr, 1e-6, 1 - 1e-6))\n",
    "\n",
    "\n",
    "def _summarise_predictions(y_true, probs, threshold):\n",
    "    preds = (probs >= threshold).astype(np.int64)\n",
    "    if preds.size == 0:\n",
    "        return {\n",
    "            'precision': 0.0,\n",
    "            'recall': 0.0,\n",
    "            'f1': 0.0,\n",
    "            'fpr': 0.0,\n",
    "            'acc': 0.0,\n",
    "            'pos_frac': 0.0,\n",
    "            'threshold': threshold,\n",
    "            'preds': preds,\n",
    "            'probs': probs,\n",
    "            'labels': y_true\n",
    "        }\n",
    "    acc = (preds == y_true).mean()\n",
    "    pr, rc, f1, _ = precision_recall_fscore_support(y_true, preds, average='binary', zero_division=0)\n",
    "    cm = confusion_matrix(y_true, preds, labels=[0, 1])\n",
    "    if cm.shape == (2, 2):\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        fpr = fp / max(tn + fp, 1)\n",
    "    else:\n",
    "        fpr = 0.0\n",
    "    pos_frac = preds.mean()\n",
    "    return {\n",
    "        'precision': float(pr),\n",
    "        'recall': float(rc),\n",
    "        'f1': float(f1),\n",
    "        'fpr': float(fpr),\n",
    "        'acc': float(acc),\n",
    "        'pos_frac': float(pos_frac),\n",
    "        'threshold': float(threshold),\n",
    "        'preds': preds,\n",
    "        'probs': probs,\n",
    "        'labels': y_true\n",
    "    }\n",
    "\n",
    "\n",
    "def _refine_threshold_with_fpr_limit(probs, labels, max_fpr, fallback_threshold):\n",
    "    if probs.size == 0:\n",
    "        return float('nan')\n",
    "    fpr, tpr, thresholds = roc_curve(labels, probs)\n",
    "    finite_mask = np.isfinite(thresholds)\n",
    "    fpr, thresholds = fpr[finite_mask], thresholds[finite_mask]\n",
    "    if thresholds.size == 0:\n",
    "        return float('nan')\n",
    "    valid_idx = np.where(fpr <= max_fpr)[0]\n",
    "    if valid_idx.size == 0:\n",
    "        return float('nan')\n",
    "    candidate = thresholds[valid_idx].max()\n",
    "    if not np.isfinite(candidate):\n",
    "        return float('nan')\n",
    "    return float(np.clip(candidate, 1e-6, 1 - 1e-6))\n",
    "\n",
    "\n",
    "def _evaluate_raw_sample(threshold):\n",
    "    if 'raw_data' not in globals():\n",
    "        return None\n",
    "    gnn.eval(); clf.eval()\n",
    "    with torch.no_grad():\n",
    "        raw_batch = raw_data.clone().to(device)\n",
    "        raw_logits = clf.score_pairs(\n",
    "            gnn(raw_batch.x, raw_batch.edge_index, raw_batch.edge_attr),\n",
    "            raw_batch.edge_index[0],\n",
    "            raw_batch.edge_index[1],\n",
    "            raw_batch.edge_attr\n",
    "        )\n",
    "        probs = torch.sigmoid(raw_logits).cpu().numpy().astype(np.float32)\n",
    "        labels = raw_batch.edge_label.cpu().numpy().astype(np.int64)\n",
    "    return _summarise_predictions(labels, probs, threshold)\n",
    "\n",
    "\n",
    "def train_one_epoch(use_amp=True, log_every=200, neg_ratio=3.0):\n",
    "    gnn.train(); clf.train()\n",
    "    amp_enabled = use_amp and (device.type == 'cuda') and not fallback_mode\n",
    "    scaler = torch.amp.GradScaler('cuda') if amp_enabled else None\n",
    "    clip_enabled = (grad_clip is not None) and (grad_clip > 0)\n",
    "    if fallback_mode:\n",
    "        optimizer.zero_grad()\n",
    "        x = gnn(data.x.to(device), data.edge_index.to(device), data.edge_attr.to(device))\n",
    "        split = fallback_splits['train']\n",
    "        labels_cpu = split['edge_label'].cpu()\n",
    "        selected_indices = _sample_balanced_indices(labels_cpu, neg_ratio)\n",
    "        if selected_indices.numel() == 0:\n",
    "            print('No positive edges found in training split; cannot update model.')\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            return float('nan')\n",
    "        total_edges = selected_indices.numel()\n",
    "        chunk_size = max(int(edge_batch_size), 1)\n",
    "        loss_terms = []\n",
    "        for edge_idx_chunk, edge_attr_chunk, label_chunk in _iter_fallback_chunks(split, chunk_size, selected_indices):\n",
    "            u = edge_idx_chunk[0].to(device)\n",
    "            v = edge_idx_chunk[1].to(device)\n",
    "            edge_attr = torch.nan_to_num(edge_attr_chunk, nan=0.0, posinf=0.0, neginf=0.0).to(device)\n",
    "            edge_label = label_chunk.to(device).float()\n",
    "            logits = clf.score_pairs(x, u, v, edge_attr)\n",
    "            loss = criterion(logits, edge_label)\n",
    "            if not torch.isfinite(loss):\n",
    "                print('Non-finite loss encountered in fallback chunk; try lowering pos_weight or learning rate.')\n",
    "                return float('nan')\n",
    "            loss_terms.append(loss * edge_label.numel())\n",
    "        if not loss_terms:\n",
    "            print('Balanced sampling produced no batches; skipping epoch.')\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            return 0.0\n",
    "        loss_total = torch.stack(loss_terms).sum() / max(total_edges, 1)\n",
    "        loss_total.backward()\n",
    "        if clip_enabled:\n",
    "            torch.nn.utils.clip_grad_norm_(params, max_norm=grad_clip)\n",
    "        optimizer.step()\n",
    "        return float(loss_total.detach().cpu())\n",
    "    # Neighbor-sampling path (backend available)\n",
    "    total_loss = 0.0\n",
    "    total_count = 0\n",
    "    t0 = time.time()\n",
    "    for i, batch in enumerate(tqdm(train_loader, desc='train_batches'), 1):\n",
    "        optimizer.zero_grad()\n",
    "        batch = batch.to(device)\n",
    "        context = torch.amp.autocast('cuda') if scaler is not None else nullcontext()\n",
    "        with context:\n",
    "            x = gnn(batch.x, batch.edge_index, batch.edge_attr)\n",
    "            label_edge_attr = _gather_label_edge_attr(batch)\n",
    "            logits = clf.score_pairs(x, batch.edge_label_index[0], batch.edge_label_index[1], label_edge_attr)\n",
    "            labels_float = batch.edge_label.float()\n",
    "            loss = criterion(logits, labels_float)\n",
    "        if not torch.isfinite(loss):\n",
    "            print(f'  batch {i} produced non-finite loss; skipping update.')\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            continue\n",
    "        if scaler is not None:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            if clip_enabled:\n",
    "                torch.nn.utils.clip_grad_norm_(params, max_norm=grad_clip)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            if clip_enabled:\n",
    "                torch.nn.utils.clip_grad_norm_(params, max_norm=grad_clip)\n",
    "            optimizer.step()\n",
    "        batch_size_local = batch.edge_label.numel()\n",
    "        total_loss += loss.item() * batch_size_local\n",
    "        total_count += batch_size_local\n",
    "        if i % max(log_every, 1) == 0:\n",
    "            print(f'  batch {i} | batch_loss {loss.item():.4f} | elapsed {time.time()-t0:.1f}s')\n",
    "    return total_loss / max(total_count, 1)\n",
    "\n",
    "\n",
    "def evaluate_split(split_name, threshold=None, calibrate=False):\n",
    "    gnn.eval(); clf.eval()\n",
    "    chunk_size = max(int(edge_batch_size), 1)\n",
    "    labels_list = []\n",
    "    probs_list = []\n",
    "    if fallback_mode:\n",
    "        split = fallback_splits[split_name]\n",
    "        with torch.no_grad():\n",
    "            x = gnn(data.x.to(device), data.edge_index.to(device), data.edge_attr.to(device))\n",
    "            for edge_idx_chunk, edge_attr_chunk, label_chunk in _iter_fallback_chunks(split, chunk_size):\n",
    "                u = edge_idx_chunk[0].to(device)\n",
    "                v = edge_idx_chunk[1].to(device)\n",
    "                edge_attr = torch.nan_to_num(edge_attr_chunk, nan=0.0, posinf=0.0, neginf=0.0).to(device)\n",
    "                logits = clf.score_pairs(x, u, v, edge_attr)\n",
    "                probs = torch.sigmoid(logits).detach().cpu()\n",
    "                probs_list.append(probs)\n",
    "                labels_list.append(label_chunk.detach().cpu())\n",
    "    else:\n",
    "        loader_map = {'train': train_loader, 'val': val_loader, 'test': test_loader}\n",
    "        loader = loader_map[split_name]\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(loader, desc=f'{split_name}_batches'):\n",
    "                batch = batch.to(device)\n",
    "                x = gnn(batch.x, batch.edge_index, batch.edge_attr)\n",
    "                label_edge_attr = _gather_label_edge_attr(batch)\n",
    "                logits = clf.score_pairs(x, batch.edge_label_index[0], batch.edge_label_index[1], label_edge_attr)\n",
    "                probs = torch.sigmoid(logits).detach().cpu()\n",
    "                probs_list.append(probs)\n",
    "                labels_list.append(batch.edge_label.detach().cpu())\n",
    "    if not labels_list:\n",
    "        empty = np.array([])\n",
    "        return {\n",
    "            'acc': 0.0,\n",
    "            'precision': 0.0,\n",
    "            'recall': 0.0,\n",
    "            'f1': 0.0,\n",
    "            'fpr': 0.0,\n",
    "            'pos_frac': 0.0,\n",
    "            'threshold': threshold if threshold is not None else 0.5,\n",
    "            'preds': empty,\n",
    "            'probs': empty,\n",
    "            'labels': empty\n",
    "        }\n",
    "    labels = torch.cat(labels_list).numpy().astype(np.int64)\n",
    "    probs = torch.cat(probs_list).numpy().astype(np.float32)\n",
    "    if calibrate or threshold is None:\n",
    "        chosen_threshold = _select_threshold(labels, probs, target_fpr=fpr_target)\n",
    "    else:\n",
    "        chosen_threshold = threshold\n",
    "    summary = _summarise_predictions(labels, probs, chosen_threshold)\n",
    "    return summary\n",
    "\n",
    "\n",
    "log_every = 200 if not fallback_mode else 0\n",
    "calibrated_threshold = 0.5\n",
    "for epoch in range(1, epochs+1):\n",
    "    epoch_t0 = time.time()\n",
    "    avg_loss = train_one_epoch(use_amp=(device.type == 'cuda'), log_every=log_every, neg_ratio=neg_pos_ratio)\n",
    "    epoch_time = time.time() - epoch_t0\n",
    "    if not math.isfinite(avg_loss):\n",
    "        print(f'Epoch {epoch:02d} skipped due to non-finite loss.')\n",
    "        continue\n",
    "    warmup_ready = epoch >= calibrate_warmup\n",
    "    should_calibrate = (epoch == 1) or (warmup_ready and ((epoch - calibrate_warmup) % max(calibrate_every, 1) == 0))\n",
    "    train_metrics = evaluate_split('train', threshold=calibrated_threshold)\n",
    "    val_metrics = evaluate_split('val', threshold=calibrated_threshold, calibrate=should_calibrate)\n",
    "    if should_calibrate:\n",
    "        new_threshold = val_metrics['threshold']\n",
    "        allow_update = np.isfinite(new_threshold)\n",
    "        if allow_update and val_metrics['pos_frac'] > max_val_pos_frac:\n",
    "            print(f\"  skip threshold update: val_pos_frac {val_metrics['pos_frac']:.3f} exceeds {max_val_pos_frac:.3f}\")\n",
    "            allow_update = False\n",
    "        if allow_update and val_metrics['fpr'] > max_val_fpr:\n",
    "            print(f\"  skip threshold update: val_fpr {val_metrics['fpr']:.3f} exceeds {max_val_fpr:.3f}\")\n",
    "            allow_update = False\n",
    "        raw_guard_metrics = None\n",
    "        if allow_update and 'raw_data' in globals():\n",
    "            baseline_guard = _evaluate_raw_sample(new_threshold)\n",
    "            if baseline_guard is not None and baseline_guard['probs'].size > 0:\n",
    "                refined_threshold = _refine_threshold_with_fpr_limit(\n",
    "                    baseline_guard['probs'],\n",
    "                    baseline_guard['labels'],\n",
    "                    max_full_sample_fpr,\n",
    "                    new_threshold\n",
    "                )\n",
    "                if not np.isfinite(refined_threshold):\n",
    "                    print(\n",
    "                        f\"  skip threshold update: raw_sample_fpr {baseline_guard['fpr']:.3f} exceeds {max_full_sample_fpr:.3f} and no tighter threshold meets the limit\"\n",
    "                    )\n",
    "                    allow_update = False\n",
    "                else:\n",
    "                    refined_threshold = float(np.clip(refined_threshold, threshold_floor, threshold_ceiling))\n",
    "                    if abs(refined_threshold - new_threshold) < 1e-6:\n",
    "                        raw_guard_metrics = baseline_guard\n",
    "                    else:\n",
    "                        raw_guard_metrics = _summarise_predictions(\n",
    "                            baseline_guard['labels'],\n",
    "                            baseline_guard['probs'],\n",
    "                            refined_threshold\n",
    "                        )\n",
    "                    if raw_guard_metrics['fpr'] > max_full_sample_fpr:\n",
    "                        print(\n",
    "                            f\"  skip threshold update: raw_sample_fpr {raw_guard_metrics['fpr']:.3f} exceeds {max_full_sample_fpr:.3f} even after adjustment\"\n",
    "                        )\n",
    "                        allow_update = False\n",
    "                        raw_guard_metrics = None\n",
    "                    else:\n",
    "                        if refined_threshold > new_threshold + 1e-6:\n",
    "                            print(\n",
    "                                f\"  raw-sample threshold raised from {new_threshold:.4f} to {refined_threshold:.4f} to respect FPR <= {max_full_sample_fpr:.3f}\"\n",
    "                            )\n",
    "                        new_threshold = refined_threshold\n",
    "            elif baseline_guard is None or baseline_guard['probs'].size == 0:\n",
    "                print('  raw-sample guard skipped: sample empty or unavailable')\n",
    "        if allow_update:\n",
    "            if epoch == 1:\n",
    "                calibrated_threshold = float(np.clip(new_threshold, threshold_floor, threshold_ceiling))\n",
    "            else:\n",
    "                blended = ((1.0 - threshold_blend) * calibrated_threshold) + (threshold_blend * new_threshold)\n",
    "                calibrated_threshold = float(np.clip(blended, threshold_floor, threshold_ceiling))\n",
    "            if raw_guard_metrics is not None:\n",
    "                print(\n",
    "                    f\"  raw-sample metrics -> precision {raw_guard_metrics['precision']:.3f}, \"\n",
    "                    f\"recall {raw_guard_metrics['recall']:.3f}, fpr {raw_guard_metrics['fpr']:.4f}\"\n",
    "                )\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d} | loss {avg_loss:.4f} | time {epoch_time:.1f}s | \"\n",
    "        f\"train_acc {train_metrics['acc']:.3f} | val_acc {val_metrics['acc']:.3f} | \"\n",
    "        f\"val_precision {val_metrics['precision']:.3f} | val_recall {val_metrics['recall']:.3f} | \"\n",
    "        f\"val_f1 {val_metrics['f1']:.3f} | val_fpr {val_metrics['fpr']:.4f} | val_thresh {calibrated_threshold:.4f} | \"\n",
    "        f\"val_pos_frac {val_metrics['pos_frac']:.5f}\"\n",
    "    )\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.670682\n",
      "Test precision: 0.001024\n",
      "Test recall: 0.330116\n",
      "Test F1: 0.002041\n",
      "False positive rate: 0.32897\n",
      "Predicted positive fraction: 0.328971\n",
      "Decision threshold: 0.95\n",
      "TN: 680849, FP: 333784, FN: 694, TP: 342\n",
      "TN: 680849, FP: 333784, FN: 694, TP: 342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "test_metrics = evaluate_split('test', threshold=calibrated_threshold)\n",
    "labels = test_metrics['labels']\n",
    "preds = test_metrics['preds']\n",
    "print('Test accuracy:', round(test_metrics['acc'], 6))\n",
    "print('Test precision:', round(test_metrics['precision'], 6))\n",
    "print('Test recall:', round(test_metrics['recall'], 6))\n",
    "print('Test F1:', round(test_metrics['f1'], 6))\n",
    "print('False positive rate:', round(test_metrics['fpr'], 6))\n",
    "print('Predicted positive fraction:', round(test_metrics['pos_frac'], 6))\n",
    "print('Decision threshold:', round(test_metrics['threshold'], 6))\n",
    "\n",
    "if labels.size > 0 and preds.size > 0:\n",
    "    cm = confusion_matrix(labels, preds, labels=[0, 1])\n",
    "    disp = ConfusionMatrixDisplay(cm, display_labels=['Non-fraud', 'Fraud'])\n",
    "    disp.plot(values_format='d')\n",
    "    if cm.shape == (2, 2):\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        print(f'TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}')\n",
    "    else:\n",
    "        print(f'Confusion matrix shape unexpected: {cm.shape}')\n",
    "else:\n",
    "    print('Not enough classes in test to compute CM/recall/FPR.')\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Full-dataset evaluation ===\n",
      "Accuracy: 0.670911\n",
      "Precision: 0.000987\n",
      "Recall: 0.318138\n",
      "F1: 0.001967\n",
      "False positive rate: 0.328729\n",
      "Predicted positive fraction: 0.328718\n",
      "Decision threshold: 0.95\n",
      "TN: 3405473, FP: 1667695, FN: 3530, TP: 1647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4391"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate on the full dataset using the trained model (reuse the in-memory graph)\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "assert 'data' in globals(), \"Construct the PyG graph before running this cell.\"\n",
    "assert 'gnn' in globals() and 'clf' in globals(), \"Train the model before running a full-dataset evaluation.\"\n",
    "\n",
    "full_batch = data.clone().to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    x_full = gnn(full_batch.x, full_batch.edge_index, full_batch.edge_attr)\n",
    "    logits_full = clf.score_pairs(\n",
    "        x_full,\n",
    "        full_batch.edge_index[0],\n",
    "        full_batch.edge_index[1],\n",
    "        full_batch.edge_attr\n",
    "    )\n",
    "    probs_full = torch.sigmoid(logits_full).cpu().numpy().astype(np.float32)\n",
    "\n",
    "labels_full = full_batch.edge_label.cpu().numpy().astype(np.int64)\n",
    "full_metrics = _summarise_predictions(labels_full, probs_full, calibrated_threshold)\n",
    "\n",
    "print('\\n=== Full-dataset evaluation ===')\n",
    "print('Accuracy:', round(full_metrics['acc'], 6))\n",
    "print('Precision:', round(full_metrics['precision'], 6))\n",
    "print('Recall:', round(full_metrics['recall'], 6))\n",
    "print('F1:', round(full_metrics['f1'], 6))\n",
    "print('False positive rate:', round(full_metrics['fpr'], 6))\n",
    "print('Predicted positive fraction:', round(full_metrics['pos_frac'], 6))\n",
    "print('Decision threshold:', round(full_metrics['threshold'], 6))\n",
    "\n",
    "if labels_full.size > 0 and full_metrics['preds'].size > 0:\n",
    "    cm_full = confusion_matrix(labels_full, full_metrics['preds'], labels=[0, 1])\n",
    "    disp_full = ConfusionMatrixDisplay(cm_full, display_labels=['Non-fraud', 'Fraud'])\n",
    "    disp_full.plot(values_format='d')\n",
    "    if cm_full.shape == (2, 2):\n",
    "        tn, fp, fn, tp = cm_full.ravel()\n",
    "        print(f'TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}')\n",
    "    else:\n",
    "        print(f'Confusion matrix shape unexpected: {cm_full.shape}')\n",
    "else:\n",
    "    print('Not enough classes to compute confusion matrix metrics on full dataset.')\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOv070Al0cK/8N1oI0v7dEu",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "csc865-anti-money-laundering-ibm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
